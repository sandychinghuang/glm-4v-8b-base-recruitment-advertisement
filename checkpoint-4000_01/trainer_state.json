{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.860267314702309,
  "eval_steps": 7000,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012150668286755772,
      "grad_norm": 1.431043267250061,
      "learning_rate": 0.0004992857142857143,
      "loss": 0.2213,
      "step": 10
    },
    {
      "epoch": 0.024301336573511544,
      "grad_norm": 0.10987292230129242,
      "learning_rate": 0.0004985714285714285,
      "loss": 0.1161,
      "step": 20
    },
    {
      "epoch": 0.03645200486026731,
      "grad_norm": 1.1645628213882446,
      "learning_rate": 0.0004978571428571429,
      "loss": 0.1447,
      "step": 30
    },
    {
      "epoch": 0.04860267314702309,
      "grad_norm": 0.702559769153595,
      "learning_rate": 0.0004971428571428571,
      "loss": 0.1013,
      "step": 40
    },
    {
      "epoch": 0.060753341433778855,
      "grad_norm": 1.4288363456726074,
      "learning_rate": 0.0004964285714285715,
      "loss": 0.1327,
      "step": 50
    },
    {
      "epoch": 0.07290400972053462,
      "grad_norm": 0.16866888105869293,
      "learning_rate": 0.0004957142857142857,
      "loss": 0.0847,
      "step": 60
    },
    {
      "epoch": 0.0850546780072904,
      "grad_norm": 0.9190846085548401,
      "learning_rate": 0.000495,
      "loss": 0.106,
      "step": 70
    },
    {
      "epoch": 0.09720534629404617,
      "grad_norm": 1.906847357749939,
      "learning_rate": 0.0004942857142857143,
      "loss": 0.1092,
      "step": 80
    },
    {
      "epoch": 0.10935601458080195,
      "grad_norm": 1.9024691581726074,
      "learning_rate": 0.0004935714285714286,
      "loss": 0.0929,
      "step": 90
    },
    {
      "epoch": 0.12150668286755771,
      "grad_norm": 0.5095921754837036,
      "learning_rate": 0.0004928571428571429,
      "loss": 0.0978,
      "step": 100
    },
    {
      "epoch": 0.1336573511543135,
      "grad_norm": 0.45751240849494934,
      "learning_rate": 0.0004921428571428571,
      "loss": 0.102,
      "step": 110
    },
    {
      "epoch": 0.14580801944106925,
      "grad_norm": 0.2374742180109024,
      "learning_rate": 0.0004914285714285715,
      "loss": 0.1048,
      "step": 120
    },
    {
      "epoch": 0.15795868772782504,
      "grad_norm": 0.62067711353302,
      "learning_rate": 0.0004907142857142857,
      "loss": 0.109,
      "step": 130
    },
    {
      "epoch": 0.1701093560145808,
      "grad_norm": 1.8927420377731323,
      "learning_rate": 0.00049,
      "loss": 0.115,
      "step": 140
    },
    {
      "epoch": 0.1822600243013366,
      "grad_norm": 0.7689045071601868,
      "learning_rate": 0.0004892857142857142,
      "loss": 0.1204,
      "step": 150
    },
    {
      "epoch": 0.19441069258809235,
      "grad_norm": 0.8347253799438477,
      "learning_rate": 0.0004885714285714286,
      "loss": 0.0976,
      "step": 160
    },
    {
      "epoch": 0.2065613608748481,
      "grad_norm": 0.6355112195014954,
      "learning_rate": 0.0004878571428571429,
      "loss": 0.0806,
      "step": 170
    },
    {
      "epoch": 0.2187120291616039,
      "grad_norm": 1.2895536422729492,
      "learning_rate": 0.00048714285714285716,
      "loss": 0.0931,
      "step": 180
    },
    {
      "epoch": 0.23086269744835966,
      "grad_norm": 0.6274580359458923,
      "learning_rate": 0.00048642857142857147,
      "loss": 0.0856,
      "step": 190
    },
    {
      "epoch": 0.24301336573511542,
      "grad_norm": 0.74189692735672,
      "learning_rate": 0.0004857142857142857,
      "loss": 0.0591,
      "step": 200
    },
    {
      "epoch": 0.2551640340218712,
      "grad_norm": 1.8205407857894897,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.0779,
      "step": 210
    },
    {
      "epoch": 0.267314702308627,
      "grad_norm": 0.5424523949623108,
      "learning_rate": 0.0004842857142857143,
      "loss": 0.0899,
      "step": 220
    },
    {
      "epoch": 0.27946537059538273,
      "grad_norm": 0.5618067383766174,
      "learning_rate": 0.0004835714285714286,
      "loss": 0.0892,
      "step": 230
    },
    {
      "epoch": 0.2916160388821385,
      "grad_norm": 1.1607836484909058,
      "learning_rate": 0.0004828571428571429,
      "loss": 0.0793,
      "step": 240
    },
    {
      "epoch": 0.3037667071688943,
      "grad_norm": 1.0596815347671509,
      "learning_rate": 0.00048214285714285715,
      "loss": 0.1102,
      "step": 250
    },
    {
      "epoch": 0.3159173754556501,
      "grad_norm": 1.3794387578964233,
      "learning_rate": 0.00048142857142857145,
      "loss": 0.0921,
      "step": 260
    },
    {
      "epoch": 0.32806804374240583,
      "grad_norm": 0.5729920864105225,
      "learning_rate": 0.0004807142857142857,
      "loss": 0.0802,
      "step": 270
    },
    {
      "epoch": 0.3402187120291616,
      "grad_norm": 0.845672607421875,
      "learning_rate": 0.00048,
      "loss": 0.0861,
      "step": 280
    },
    {
      "epoch": 0.35236938031591736,
      "grad_norm": 0.2632475793361664,
      "learning_rate": 0.00047928571428571427,
      "loss": 0.0926,
      "step": 290
    },
    {
      "epoch": 0.3645200486026732,
      "grad_norm": 0.322496235370636,
      "learning_rate": 0.0004785714285714286,
      "loss": 0.0833,
      "step": 300
    },
    {
      "epoch": 0.37667071688942894,
      "grad_norm": 1.9636679887771606,
      "learning_rate": 0.0004778571428571429,
      "loss": 0.0773,
      "step": 310
    },
    {
      "epoch": 0.3888213851761847,
      "grad_norm": 0.2513749599456787,
      "learning_rate": 0.00047714285714285713,
      "loss": 0.0526,
      "step": 320
    },
    {
      "epoch": 0.40097205346294046,
      "grad_norm": 0.3189690113067627,
      "learning_rate": 0.00047642857142857144,
      "loss": 0.0587,
      "step": 330
    },
    {
      "epoch": 0.4131227217496962,
      "grad_norm": 0.3698618412017822,
      "learning_rate": 0.0004757142857142857,
      "loss": 0.092,
      "step": 340
    },
    {
      "epoch": 0.425273390036452,
      "grad_norm": 0.2495887130498886,
      "learning_rate": 0.000475,
      "loss": 0.0869,
      "step": 350
    },
    {
      "epoch": 0.4374240583232078,
      "grad_norm": 1.023608922958374,
      "learning_rate": 0.0004742857142857143,
      "loss": 0.0777,
      "step": 360
    },
    {
      "epoch": 0.44957472660996356,
      "grad_norm": 0.6301988363265991,
      "learning_rate": 0.0004735714285714286,
      "loss": 0.0972,
      "step": 370
    },
    {
      "epoch": 0.4617253948967193,
      "grad_norm": 1.733196496963501,
      "learning_rate": 0.00047285714285714287,
      "loss": 0.0844,
      "step": 380
    },
    {
      "epoch": 0.4738760631834751,
      "grad_norm": 0.18001355230808258,
      "learning_rate": 0.0004721428571428572,
      "loss": 0.0841,
      "step": 390
    },
    {
      "epoch": 0.48602673147023084,
      "grad_norm": 0.5521305203437805,
      "learning_rate": 0.0004714285714285714,
      "loss": 0.0854,
      "step": 400
    },
    {
      "epoch": 0.49817739975698666,
      "grad_norm": 0.627066433429718,
      "learning_rate": 0.00047071428571428573,
      "loss": 0.078,
      "step": 410
    },
    {
      "epoch": 0.5103280680437424,
      "grad_norm": 0.6320807337760925,
      "learning_rate": 0.00047,
      "loss": 0.121,
      "step": 420
    },
    {
      "epoch": 0.5224787363304981,
      "grad_norm": 0.8483209609985352,
      "learning_rate": 0.0004692857142857143,
      "loss": 0.077,
      "step": 430
    },
    {
      "epoch": 0.534629404617254,
      "grad_norm": 0.09041550010442734,
      "learning_rate": 0.0004685714285714286,
      "loss": 0.0632,
      "step": 440
    },
    {
      "epoch": 0.5467800729040098,
      "grad_norm": 2.5838849544525146,
      "learning_rate": 0.00046785714285714285,
      "loss": 0.1068,
      "step": 450
    },
    {
      "epoch": 0.5589307411907655,
      "grad_norm": 3.004972219467163,
      "learning_rate": 0.00046714285714285716,
      "loss": 0.1457,
      "step": 460
    },
    {
      "epoch": 0.5710814094775213,
      "grad_norm": 0.26856425404548645,
      "learning_rate": 0.0004664285714285714,
      "loss": 0.0828,
      "step": 470
    },
    {
      "epoch": 0.583232077764277,
      "grad_norm": 0.9464213252067566,
      "learning_rate": 0.0004657142857142857,
      "loss": 0.0802,
      "step": 480
    },
    {
      "epoch": 0.5953827460510328,
      "grad_norm": 1.414009928703308,
      "learning_rate": 0.000465,
      "loss": 0.101,
      "step": 490
    },
    {
      "epoch": 0.6075334143377886,
      "grad_norm": 0.9466885924339294,
      "learning_rate": 0.00046428571428571433,
      "loss": 0.1056,
      "step": 500
    },
    {
      "epoch": 0.6196840826245443,
      "grad_norm": 0.5711553692817688,
      "learning_rate": 0.0004635714285714286,
      "loss": 0.0774,
      "step": 510
    },
    {
      "epoch": 0.6318347509113001,
      "grad_norm": 0.7651182413101196,
      "learning_rate": 0.00046285714285714284,
      "loss": 0.11,
      "step": 520
    },
    {
      "epoch": 0.6439854191980559,
      "grad_norm": 0.9272531270980835,
      "learning_rate": 0.00046214285714285715,
      "loss": 0.074,
      "step": 530
    },
    {
      "epoch": 0.6561360874848117,
      "grad_norm": 0.1796419322490692,
      "learning_rate": 0.0004614285714285714,
      "loss": 0.0704,
      "step": 540
    },
    {
      "epoch": 0.6682867557715675,
      "grad_norm": 0.6078479290008545,
      "learning_rate": 0.0004607142857142857,
      "loss": 0.0825,
      "step": 550
    },
    {
      "epoch": 0.6804374240583232,
      "grad_norm": 0.9008575081825256,
      "learning_rate": 0.00046,
      "loss": 0.0785,
      "step": 560
    },
    {
      "epoch": 0.692588092345079,
      "grad_norm": 0.5489697456359863,
      "learning_rate": 0.0004592857142857143,
      "loss": 0.0821,
      "step": 570
    },
    {
      "epoch": 0.7047387606318347,
      "grad_norm": 1.1551562547683716,
      "learning_rate": 0.0004585714285714286,
      "loss": 0.0853,
      "step": 580
    },
    {
      "epoch": 0.7168894289185905,
      "grad_norm": 0.5088106393814087,
      "learning_rate": 0.0004578571428571429,
      "loss": 0.0738,
      "step": 590
    },
    {
      "epoch": 0.7290400972053463,
      "grad_norm": 0.427077978849411,
      "learning_rate": 0.00045714285714285713,
      "loss": 0.1006,
      "step": 600
    },
    {
      "epoch": 0.741190765492102,
      "grad_norm": 0.7042312622070312,
      "learning_rate": 0.00045642857142857144,
      "loss": 0.0617,
      "step": 610
    },
    {
      "epoch": 0.7533414337788579,
      "grad_norm": 0.2918197512626648,
      "learning_rate": 0.00045571428571428575,
      "loss": 0.0812,
      "step": 620
    },
    {
      "epoch": 0.7654921020656136,
      "grad_norm": 0.5144335031509399,
      "learning_rate": 0.000455,
      "loss": 0.0764,
      "step": 630
    },
    {
      "epoch": 0.7776427703523694,
      "grad_norm": 0.9804547429084778,
      "learning_rate": 0.0004542857142857143,
      "loss": 0.0709,
      "step": 640
    },
    {
      "epoch": 0.7897934386391251,
      "grad_norm": 0.5838712453842163,
      "learning_rate": 0.00045357142857142856,
      "loss": 0.0718,
      "step": 650
    },
    {
      "epoch": 0.8019441069258809,
      "grad_norm": 1.533613920211792,
      "learning_rate": 0.00045285714285714287,
      "loss": 0.0718,
      "step": 660
    },
    {
      "epoch": 0.8140947752126367,
      "grad_norm": 0.2982635796070099,
      "learning_rate": 0.0004521428571428571,
      "loss": 0.0843,
      "step": 670
    },
    {
      "epoch": 0.8262454434993924,
      "grad_norm": 0.7678006291389465,
      "learning_rate": 0.00045142857142857143,
      "loss": 0.0809,
      "step": 680
    },
    {
      "epoch": 0.8383961117861483,
      "grad_norm": 0.23952490091323853,
      "learning_rate": 0.00045071428571428573,
      "loss": 0.071,
      "step": 690
    },
    {
      "epoch": 0.850546780072904,
      "grad_norm": 1.3117341995239258,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.0878,
      "step": 700
    },
    {
      "epoch": 0.8626974483596598,
      "grad_norm": 1.2071256637573242,
      "learning_rate": 0.0004492857142857143,
      "loss": 0.0777,
      "step": 710
    },
    {
      "epoch": 0.8748481166464156,
      "grad_norm": 0.6383942365646362,
      "learning_rate": 0.0004485714285714286,
      "loss": 0.0661,
      "step": 720
    },
    {
      "epoch": 0.8869987849331713,
      "grad_norm": 0.4747936427593231,
      "learning_rate": 0.00044785714285714285,
      "loss": 0.0599,
      "step": 730
    },
    {
      "epoch": 0.8991494532199271,
      "grad_norm": 0.4525594413280487,
      "learning_rate": 0.0004471428571428571,
      "loss": 0.0541,
      "step": 740
    },
    {
      "epoch": 0.9113001215066828,
      "grad_norm": 0.7605190277099609,
      "learning_rate": 0.00044642857142857147,
      "loss": 0.0731,
      "step": 750
    },
    {
      "epoch": 0.9234507897934386,
      "grad_norm": 3.515868663787842,
      "learning_rate": 0.0004457142857142857,
      "loss": 0.0653,
      "step": 760
    },
    {
      "epoch": 0.9356014580801945,
      "grad_norm": 0.9740414023399353,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.0636,
      "step": 770
    },
    {
      "epoch": 0.9477521263669502,
      "grad_norm": 1.52834153175354,
      "learning_rate": 0.0004442857142857143,
      "loss": 0.1416,
      "step": 780
    },
    {
      "epoch": 0.959902794653706,
      "grad_norm": 2.2969717979431152,
      "learning_rate": 0.0004435714285714286,
      "loss": 0.0932,
      "step": 790
    },
    {
      "epoch": 0.9720534629404617,
      "grad_norm": 0.3382456600666046,
      "learning_rate": 0.00044285714285714284,
      "loss": 0.0837,
      "step": 800
    },
    {
      "epoch": 0.9842041312272175,
      "grad_norm": 0.06928376853466034,
      "learning_rate": 0.00044214285714285715,
      "loss": 0.0577,
      "step": 810
    },
    {
      "epoch": 0.9963547995139733,
      "grad_norm": 0.7746064066886902,
      "learning_rate": 0.00044142857142857146,
      "loss": 0.087,
      "step": 820
    },
    {
      "epoch": 1.008505467800729,
      "grad_norm": 0.586159348487854,
      "learning_rate": 0.0004407142857142857,
      "loss": 0.0613,
      "step": 830
    },
    {
      "epoch": 1.0206561360874848,
      "grad_norm": 1.6024384498596191,
      "learning_rate": 0.00044,
      "loss": 0.0754,
      "step": 840
    },
    {
      "epoch": 1.0328068043742407,
      "grad_norm": 0.558760404586792,
      "learning_rate": 0.00043928571428571427,
      "loss": 0.0547,
      "step": 850
    },
    {
      "epoch": 1.0449574726609963,
      "grad_norm": 1.8029204607009888,
      "learning_rate": 0.0004385714285714286,
      "loss": 0.0669,
      "step": 860
    },
    {
      "epoch": 1.057108140947752,
      "grad_norm": 0.347145676612854,
      "learning_rate": 0.00043785714285714283,
      "loss": 0.064,
      "step": 870
    },
    {
      "epoch": 1.069258809234508,
      "grad_norm": 0.17321164906024933,
      "learning_rate": 0.0004371428571428572,
      "loss": 0.0543,
      "step": 880
    },
    {
      "epoch": 1.0814094775212637,
      "grad_norm": 1.1310126781463623,
      "learning_rate": 0.00043642857142857144,
      "loss": 0.0539,
      "step": 890
    },
    {
      "epoch": 1.0935601458080195,
      "grad_norm": 0.08711511641740799,
      "learning_rate": 0.00043571428571428575,
      "loss": 0.0629,
      "step": 900
    },
    {
      "epoch": 1.1057108140947751,
      "grad_norm": 0.4862889051437378,
      "learning_rate": 0.000435,
      "loss": 0.0591,
      "step": 910
    },
    {
      "epoch": 1.117861482381531,
      "grad_norm": 0.22564402222633362,
      "learning_rate": 0.0004342857142857143,
      "loss": 0.0724,
      "step": 920
    },
    {
      "epoch": 1.1300121506682868,
      "grad_norm": 0.21491172909736633,
      "learning_rate": 0.00043357142857142856,
      "loss": 0.0553,
      "step": 930
    },
    {
      "epoch": 1.1421628189550426,
      "grad_norm": 0.7271234393119812,
      "learning_rate": 0.00043285714285714287,
      "loss": 0.1076,
      "step": 940
    },
    {
      "epoch": 1.1543134872417984,
      "grad_norm": 0.2344231754541397,
      "learning_rate": 0.0004321428571428572,
      "loss": 0.0623,
      "step": 950
    },
    {
      "epoch": 1.166464155528554,
      "grad_norm": 0.3656221032142639,
      "learning_rate": 0.00043142857142857143,
      "loss": 0.0732,
      "step": 960
    },
    {
      "epoch": 1.1786148238153098,
      "grad_norm": 0.8804159760475159,
      "learning_rate": 0.00043071428571428574,
      "loss": 0.0913,
      "step": 970
    },
    {
      "epoch": 1.1907654921020656,
      "grad_norm": 0.17601364850997925,
      "learning_rate": 0.00043,
      "loss": 0.0653,
      "step": 980
    },
    {
      "epoch": 1.2029161603888214,
      "grad_norm": 0.5061924457550049,
      "learning_rate": 0.0004292857142857143,
      "loss": 0.0635,
      "step": 990
    },
    {
      "epoch": 1.2150668286755772,
      "grad_norm": 0.31447455286979675,
      "learning_rate": 0.00042857142857142855,
      "loss": 0.0522,
      "step": 1000
    },
    {
      "epoch": 1.2272174969623328,
      "grad_norm": 0.14698460698127747,
      "learning_rate": 0.0004278571428571429,
      "loss": 0.0587,
      "step": 1010
    },
    {
      "epoch": 1.2393681652490887,
      "grad_norm": 0.7912541031837463,
      "learning_rate": 0.00042714285714285716,
      "loss": 0.0631,
      "step": 1020
    },
    {
      "epoch": 1.2515188335358445,
      "grad_norm": 0.5578683614730835,
      "learning_rate": 0.0004264285714285714,
      "loss": 0.068,
      "step": 1030
    },
    {
      "epoch": 1.2636695018226003,
      "grad_norm": 0.5059112310409546,
      "learning_rate": 0.0004257142857142857,
      "loss": 0.0631,
      "step": 1040
    },
    {
      "epoch": 1.2758201701093559,
      "grad_norm": 0.7580945491790771,
      "learning_rate": 0.000425,
      "loss": 0.0671,
      "step": 1050
    },
    {
      "epoch": 1.2879708383961117,
      "grad_norm": 0.49606093764305115,
      "learning_rate": 0.0004242857142857143,
      "loss": 0.067,
      "step": 1060
    },
    {
      "epoch": 1.3001215066828675,
      "grad_norm": 0.6519622802734375,
      "learning_rate": 0.0004235714285714286,
      "loss": 0.0449,
      "step": 1070
    },
    {
      "epoch": 1.3122721749696233,
      "grad_norm": 0.8724130988121033,
      "learning_rate": 0.0004228571428571429,
      "loss": 0.0573,
      "step": 1080
    },
    {
      "epoch": 1.3244228432563792,
      "grad_norm": 1.0269618034362793,
      "learning_rate": 0.00042214285714285715,
      "loss": 0.0689,
      "step": 1090
    },
    {
      "epoch": 1.336573511543135,
      "grad_norm": 0.2300809621810913,
      "learning_rate": 0.00042142857142857146,
      "loss": 0.0583,
      "step": 1100
    },
    {
      "epoch": 1.3487241798298906,
      "grad_norm": 1.0011595487594604,
      "learning_rate": 0.0004207142857142857,
      "loss": 0.0563,
      "step": 1110
    },
    {
      "epoch": 1.3608748481166464,
      "grad_norm": 1.2759250402450562,
      "learning_rate": 0.00042,
      "loss": 0.0545,
      "step": 1120
    },
    {
      "epoch": 1.3730255164034022,
      "grad_norm": 0.24537882208824158,
      "learning_rate": 0.00041928571428571427,
      "loss": 0.0602,
      "step": 1130
    },
    {
      "epoch": 1.385176184690158,
      "grad_norm": 0.5630513429641724,
      "learning_rate": 0.0004185714285714286,
      "loss": 0.0503,
      "step": 1140
    },
    {
      "epoch": 1.3973268529769136,
      "grad_norm": 0.7182013392448425,
      "learning_rate": 0.0004178571428571429,
      "loss": 0.0545,
      "step": 1150
    },
    {
      "epoch": 1.4094775212636694,
      "grad_norm": 0.4580583870410919,
      "learning_rate": 0.00041714285714285714,
      "loss": 0.0702,
      "step": 1160
    },
    {
      "epoch": 1.4216281895504252,
      "grad_norm": 0.3141566216945648,
      "learning_rate": 0.00041642857142857144,
      "loss": 0.0505,
      "step": 1170
    },
    {
      "epoch": 1.433778857837181,
      "grad_norm": 1.0220396518707275,
      "learning_rate": 0.0004157142857142857,
      "loss": 0.0455,
      "step": 1180
    },
    {
      "epoch": 1.4459295261239369,
      "grad_norm": 0.282325804233551,
      "learning_rate": 0.000415,
      "loss": 0.0633,
      "step": 1190
    },
    {
      "epoch": 1.4580801944106927,
      "grad_norm": 0.2260119616985321,
      "learning_rate": 0.0004142857142857143,
      "loss": 0.0499,
      "step": 1200
    },
    {
      "epoch": 1.4702308626974483,
      "grad_norm": 0.17742471396923065,
      "learning_rate": 0.0004135714285714286,
      "loss": 0.0677,
      "step": 1210
    },
    {
      "epoch": 1.482381530984204,
      "grad_norm": 0.45928266644477844,
      "learning_rate": 0.00041285714285714287,
      "loss": 0.0523,
      "step": 1220
    },
    {
      "epoch": 1.49453219927096,
      "grad_norm": 0.7548456788063049,
      "learning_rate": 0.0004121428571428572,
      "loss": 0.0649,
      "step": 1230
    },
    {
      "epoch": 1.5066828675577155,
      "grad_norm": 0.12281491607427597,
      "learning_rate": 0.00041142857142857143,
      "loss": 0.0543,
      "step": 1240
    },
    {
      "epoch": 1.5188335358444713,
      "grad_norm": 2.4644622802734375,
      "learning_rate": 0.0004107142857142857,
      "loss": 0.0802,
      "step": 1250
    },
    {
      "epoch": 1.5309842041312272,
      "grad_norm": 0.7650943398475647,
      "learning_rate": 0.00041,
      "loss": 0.0599,
      "step": 1260
    },
    {
      "epoch": 1.543134872417983,
      "grad_norm": 0.9905595183372498,
      "learning_rate": 0.0004092857142857143,
      "loss": 0.0613,
      "step": 1270
    },
    {
      "epoch": 1.5552855407047388,
      "grad_norm": 0.4689171612262726,
      "learning_rate": 0.0004085714285714286,
      "loss": 0.0708,
      "step": 1280
    },
    {
      "epoch": 1.5674362089914946,
      "grad_norm": 0.24212339520454407,
      "learning_rate": 0.00040785714285714286,
      "loss": 0.051,
      "step": 1290
    },
    {
      "epoch": 1.5795868772782504,
      "grad_norm": 0.13841919600963593,
      "learning_rate": 0.00040714285714285717,
      "loss": 0.0622,
      "step": 1300
    },
    {
      "epoch": 1.5917375455650062,
      "grad_norm": 0.9713994264602661,
      "learning_rate": 0.0004064285714285714,
      "loss": 0.0648,
      "step": 1310
    },
    {
      "epoch": 1.6038882138517618,
      "grad_norm": 1.1322816610336304,
      "learning_rate": 0.0004057142857142857,
      "loss": 0.0822,
      "step": 1320
    },
    {
      "epoch": 1.6160388821385177,
      "grad_norm": 0.045320652425289154,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.067,
      "step": 1330
    },
    {
      "epoch": 1.6281895504252732,
      "grad_norm": 1.2748494148254395,
      "learning_rate": 0.0004042857142857143,
      "loss": 0.0665,
      "step": 1340
    },
    {
      "epoch": 1.640340218712029,
      "grad_norm": 0.5538387298583984,
      "learning_rate": 0.0004035714285714286,
      "loss": 0.0491,
      "step": 1350
    },
    {
      "epoch": 1.6524908869987849,
      "grad_norm": 1.112054467201233,
      "learning_rate": 0.00040285714285714285,
      "loss": 0.0705,
      "step": 1360
    },
    {
      "epoch": 1.6646415552855407,
      "grad_norm": 0.6752188801765442,
      "learning_rate": 0.00040214285714285715,
      "loss": 0.0589,
      "step": 1370
    },
    {
      "epoch": 1.6767922235722965,
      "grad_norm": 1.5080738067626953,
      "learning_rate": 0.0004014285714285714,
      "loss": 0.0724,
      "step": 1380
    },
    {
      "epoch": 1.6889428918590523,
      "grad_norm": 1.5280070304870605,
      "learning_rate": 0.0004007142857142857,
      "loss": 0.0515,
      "step": 1390
    },
    {
      "epoch": 1.7010935601458081,
      "grad_norm": 1.570929765701294,
      "learning_rate": 0.0004,
      "loss": 0.0609,
      "step": 1400
    },
    {
      "epoch": 1.7132442284325637,
      "grad_norm": 1.0060017108917236,
      "learning_rate": 0.0003992857142857143,
      "loss": 0.0638,
      "step": 1410
    },
    {
      "epoch": 1.7253948967193196,
      "grad_norm": 0.22645694017410278,
      "learning_rate": 0.0003985714285714286,
      "loss": 0.062,
      "step": 1420
    },
    {
      "epoch": 1.7375455650060754,
      "grad_norm": 0.4972825348377228,
      "learning_rate": 0.0003978571428571429,
      "loss": 0.0596,
      "step": 1430
    },
    {
      "epoch": 1.749696233292831,
      "grad_norm": 0.5890862345695496,
      "learning_rate": 0.00039714285714285714,
      "loss": 0.0541,
      "step": 1440
    },
    {
      "epoch": 1.7618469015795868,
      "grad_norm": 0.8727283477783203,
      "learning_rate": 0.0003964285714285714,
      "loss": 0.0491,
      "step": 1450
    },
    {
      "epoch": 1.7739975698663426,
      "grad_norm": 1.147533655166626,
      "learning_rate": 0.00039571428571428575,
      "loss": 0.0553,
      "step": 1460
    },
    {
      "epoch": 1.7861482381530984,
      "grad_norm": 0.04414895549416542,
      "learning_rate": 0.000395,
      "loss": 0.0524,
      "step": 1470
    },
    {
      "epoch": 1.7982989064398542,
      "grad_norm": 0.7040407061576843,
      "learning_rate": 0.0003942857142857143,
      "loss": 0.0683,
      "step": 1480
    },
    {
      "epoch": 1.81044957472661,
      "grad_norm": 0.916872501373291,
      "learning_rate": 0.00039357142857142857,
      "loss": 0.0617,
      "step": 1490
    },
    {
      "epoch": 1.8226002430133659,
      "grad_norm": 0.5367171764373779,
      "learning_rate": 0.0003928571428571429,
      "loss": 0.0673,
      "step": 1500
    },
    {
      "epoch": 1.8347509113001215,
      "grad_norm": 0.6431311964988708,
      "learning_rate": 0.0003921428571428571,
      "loss": 0.0586,
      "step": 1510
    },
    {
      "epoch": 1.8469015795868773,
      "grad_norm": 0.3520583510398865,
      "learning_rate": 0.00039142857142857143,
      "loss": 0.0683,
      "step": 1520
    },
    {
      "epoch": 1.859052247873633,
      "grad_norm": 0.6784937381744385,
      "learning_rate": 0.00039071428571428574,
      "loss": 0.0524,
      "step": 1530
    },
    {
      "epoch": 1.8712029161603887,
      "grad_norm": 0.7237421870231628,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.0497,
      "step": 1540
    },
    {
      "epoch": 1.8833535844471445,
      "grad_norm": 1.0903385877609253,
      "learning_rate": 0.0003892857142857143,
      "loss": 0.0397,
      "step": 1550
    },
    {
      "epoch": 1.8955042527339003,
      "grad_norm": 0.2622557282447815,
      "learning_rate": 0.00038857142857142855,
      "loss": 0.0466,
      "step": 1560
    },
    {
      "epoch": 1.9076549210206561,
      "grad_norm": 0.7598969340324402,
      "learning_rate": 0.00038785714285714286,
      "loss": 0.0627,
      "step": 1570
    },
    {
      "epoch": 1.919805589307412,
      "grad_norm": 0.5175855755805969,
      "learning_rate": 0.0003871428571428571,
      "loss": 0.047,
      "step": 1580
    },
    {
      "epoch": 1.9319562575941678,
      "grad_norm": 0.415242463350296,
      "learning_rate": 0.0003864285714285715,
      "loss": 0.0863,
      "step": 1590
    },
    {
      "epoch": 1.9441069258809236,
      "grad_norm": 0.19887550175189972,
      "learning_rate": 0.0003857142857142857,
      "loss": 0.0508,
      "step": 1600
    },
    {
      "epoch": 1.9562575941676792,
      "grad_norm": 0.4850284457206726,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.0488,
      "step": 1610
    },
    {
      "epoch": 1.968408262454435,
      "grad_norm": 0.3349211513996124,
      "learning_rate": 0.0003842857142857143,
      "loss": 0.0535,
      "step": 1620
    },
    {
      "epoch": 1.9805589307411906,
      "grad_norm": 1.0137370824813843,
      "learning_rate": 0.0003835714285714286,
      "loss": 0.0792,
      "step": 1630
    },
    {
      "epoch": 1.9927095990279464,
      "grad_norm": 0.8014339804649353,
      "learning_rate": 0.00038285714285714285,
      "loss": 0.0618,
      "step": 1640
    },
    {
      "epoch": 2.0048602673147022,
      "grad_norm": 0.16845601797103882,
      "learning_rate": 0.0003821428571428571,
      "loss": 0.0713,
      "step": 1650
    },
    {
      "epoch": 2.017010935601458,
      "grad_norm": 0.2177581787109375,
      "learning_rate": 0.00038142857142857146,
      "loss": 0.0462,
      "step": 1660
    },
    {
      "epoch": 2.029161603888214,
      "grad_norm": 0.35089030861854553,
      "learning_rate": 0.0003807142857142857,
      "loss": 0.0458,
      "step": 1670
    },
    {
      "epoch": 2.0413122721749697,
      "grad_norm": 0.91242516040802,
      "learning_rate": 0.00038,
      "loss": 0.0409,
      "step": 1680
    },
    {
      "epoch": 2.0534629404617255,
      "grad_norm": 0.3862905502319336,
      "learning_rate": 0.0003792857142857143,
      "loss": 0.0509,
      "step": 1690
    },
    {
      "epoch": 2.0656136087484813,
      "grad_norm": 0.7059670090675354,
      "learning_rate": 0.0003785714285714286,
      "loss": 0.0664,
      "step": 1700
    },
    {
      "epoch": 2.077764277035237,
      "grad_norm": 0.8730612397193909,
      "learning_rate": 0.00037785714285714283,
      "loss": 0.045,
      "step": 1710
    },
    {
      "epoch": 2.0899149453219925,
      "grad_norm": 0.4172361493110657,
      "learning_rate": 0.0003771428571428572,
      "loss": 0.0421,
      "step": 1720
    },
    {
      "epoch": 2.1020656136087483,
      "grad_norm": 0.34990382194519043,
      "learning_rate": 0.00037642857142857145,
      "loss": 0.0578,
      "step": 1730
    },
    {
      "epoch": 2.114216281895504,
      "grad_norm": 0.6873847842216492,
      "learning_rate": 0.00037571428571428575,
      "loss": 0.0464,
      "step": 1740
    },
    {
      "epoch": 2.12636695018226,
      "grad_norm": 0.19600465893745422,
      "learning_rate": 0.000375,
      "loss": 0.0415,
      "step": 1750
    },
    {
      "epoch": 2.138517618469016,
      "grad_norm": 0.7377595901489258,
      "learning_rate": 0.00037428571428571426,
      "loss": 0.0357,
      "step": 1760
    },
    {
      "epoch": 2.1506682867557716,
      "grad_norm": 0.9458242654800415,
      "learning_rate": 0.00037357142857142857,
      "loss": 0.0556,
      "step": 1770
    },
    {
      "epoch": 2.1628189550425274,
      "grad_norm": 0.6733870506286621,
      "learning_rate": 0.0003728571428571428,
      "loss": 0.0442,
      "step": 1780
    },
    {
      "epoch": 2.1749696233292832,
      "grad_norm": 0.6071048378944397,
      "learning_rate": 0.0003721428571428572,
      "loss": 0.0424,
      "step": 1790
    },
    {
      "epoch": 2.187120291616039,
      "grad_norm": 0.13309118151664734,
      "learning_rate": 0.00037142857142857143,
      "loss": 0.0475,
      "step": 1800
    },
    {
      "epoch": 2.199270959902795,
      "grad_norm": 0.020688075572252274,
      "learning_rate": 0.00037071428571428574,
      "loss": 0.0525,
      "step": 1810
    },
    {
      "epoch": 2.2114216281895502,
      "grad_norm": 0.9419683218002319,
      "learning_rate": 0.00037,
      "loss": 0.0412,
      "step": 1820
    },
    {
      "epoch": 2.223572296476306,
      "grad_norm": 0.4305945336818695,
      "learning_rate": 0.0003692857142857143,
      "loss": 0.0879,
      "step": 1830
    },
    {
      "epoch": 2.235722964763062,
      "grad_norm": 0.05850221589207649,
      "learning_rate": 0.00036857142857142855,
      "loss": 0.0483,
      "step": 1840
    },
    {
      "epoch": 2.2478736330498177,
      "grad_norm": 0.20848548412322998,
      "learning_rate": 0.0003678571428571429,
      "loss": 0.0411,
      "step": 1850
    },
    {
      "epoch": 2.2600243013365735,
      "grad_norm": 0.314779669046402,
      "learning_rate": 0.00036714285714285717,
      "loss": 0.0479,
      "step": 1860
    },
    {
      "epoch": 2.2721749696233293,
      "grad_norm": 0.3118896782398224,
      "learning_rate": 0.0003664285714285714,
      "loss": 0.0473,
      "step": 1870
    },
    {
      "epoch": 2.284325637910085,
      "grad_norm": 1.002021074295044,
      "learning_rate": 0.00036571428571428573,
      "loss": 0.0458,
      "step": 1880
    },
    {
      "epoch": 2.296476306196841,
      "grad_norm": 0.9276431798934937,
      "learning_rate": 0.000365,
      "loss": 0.0467,
      "step": 1890
    },
    {
      "epoch": 2.3086269744835968,
      "grad_norm": 0.3484906852245331,
      "learning_rate": 0.0003642857142857143,
      "loss": 0.0597,
      "step": 1900
    },
    {
      "epoch": 2.320777642770352,
      "grad_norm": 0.12691457569599152,
      "learning_rate": 0.00036357142857142854,
      "loss": 0.0392,
      "step": 1910
    },
    {
      "epoch": 2.332928311057108,
      "grad_norm": 0.05309142917394638,
      "learning_rate": 0.0003628571428571429,
      "loss": 0.0401,
      "step": 1920
    },
    {
      "epoch": 2.345078979343864,
      "grad_norm": 0.28370335698127747,
      "learning_rate": 0.00036214285714285716,
      "loss": 0.0481,
      "step": 1930
    },
    {
      "epoch": 2.3572296476306196,
      "grad_norm": 0.7474308013916016,
      "learning_rate": 0.00036142857142857146,
      "loss": 0.0679,
      "step": 1940
    },
    {
      "epoch": 2.3693803159173754,
      "grad_norm": 1.3245073556900024,
      "learning_rate": 0.0003607142857142857,
      "loss": 0.0489,
      "step": 1950
    },
    {
      "epoch": 2.3815309842041312,
      "grad_norm": 0.24759718775749207,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.0464,
      "step": 1960
    },
    {
      "epoch": 2.393681652490887,
      "grad_norm": 0.06146815046668053,
      "learning_rate": 0.0003592857142857143,
      "loss": 0.0435,
      "step": 1970
    },
    {
      "epoch": 2.405832320777643,
      "grad_norm": 0.8629549145698547,
      "learning_rate": 0.0003585714285714286,
      "loss": 0.0542,
      "step": 1980
    },
    {
      "epoch": 2.4179829890643987,
      "grad_norm": 0.09856268763542175,
      "learning_rate": 0.0003578571428571429,
      "loss": 0.0611,
      "step": 1990
    },
    {
      "epoch": 2.4301336573511545,
      "grad_norm": 0.20193244516849518,
      "learning_rate": 0.00035714285714285714,
      "loss": 0.0515,
      "step": 2000
    },
    {
      "epoch": 2.4422843256379103,
      "grad_norm": 0.20952878892421722,
      "learning_rate": 0.00035642857142857145,
      "loss": 0.0528,
      "step": 2010
    },
    {
      "epoch": 2.4544349939246657,
      "grad_norm": 3.8161120414733887,
      "learning_rate": 0.0003557142857142857,
      "loss": 0.0397,
      "step": 2020
    },
    {
      "epoch": 2.4665856622114215,
      "grad_norm": 0.09994623064994812,
      "learning_rate": 0.000355,
      "loss": 0.0484,
      "step": 2030
    },
    {
      "epoch": 2.4787363304981773,
      "grad_norm": 0.3075393736362457,
      "learning_rate": 0.00035428571428571426,
      "loss": 0.0503,
      "step": 2040
    },
    {
      "epoch": 2.490886998784933,
      "grad_norm": 0.2313823401927948,
      "learning_rate": 0.0003535714285714286,
      "loss": 0.0611,
      "step": 2050
    },
    {
      "epoch": 2.503037667071689,
      "grad_norm": 0.3176080286502838,
      "learning_rate": 0.0003528571428571429,
      "loss": 0.042,
      "step": 2060
    },
    {
      "epoch": 2.5151883353584448,
      "grad_norm": 0.012662539258599281,
      "learning_rate": 0.00035214285714285713,
      "loss": 0.0782,
      "step": 2070
    },
    {
      "epoch": 2.5273390036452006,
      "grad_norm": 0.36718663573265076,
      "learning_rate": 0.00035142857142857144,
      "loss": 0.0342,
      "step": 2080
    },
    {
      "epoch": 2.5394896719319564,
      "grad_norm": 0.48333239555358887,
      "learning_rate": 0.0003507142857142857,
      "loss": 0.045,
      "step": 2090
    },
    {
      "epoch": 2.5516403402187118,
      "grad_norm": 0.050110600888729095,
      "learning_rate": 0.00035,
      "loss": 0.065,
      "step": 2100
    },
    {
      "epoch": 2.5637910085054676,
      "grad_norm": 1.4868416786193848,
      "learning_rate": 0.0003492857142857143,
      "loss": 0.0479,
      "step": 2110
    },
    {
      "epoch": 2.5759416767922234,
      "grad_norm": 0.9337213039398193,
      "learning_rate": 0.0003485714285714286,
      "loss": 0.0482,
      "step": 2120
    },
    {
      "epoch": 2.5880923450789792,
      "grad_norm": 0.16396410763263702,
      "learning_rate": 0.00034785714285714286,
      "loss": 0.0427,
      "step": 2130
    },
    {
      "epoch": 2.600243013365735,
      "grad_norm": 0.2059212177991867,
      "learning_rate": 0.00034714285714285717,
      "loss": 0.0597,
      "step": 2140
    },
    {
      "epoch": 2.612393681652491,
      "grad_norm": 0.18197445571422577,
      "learning_rate": 0.0003464285714285714,
      "loss": 0.0436,
      "step": 2150
    },
    {
      "epoch": 2.6245443499392467,
      "grad_norm": 0.49079179763793945,
      "learning_rate": 0.00034571428571428573,
      "loss": 0.046,
      "step": 2160
    },
    {
      "epoch": 2.6366950182260025,
      "grad_norm": 0.024822000414133072,
      "learning_rate": 0.000345,
      "loss": 0.0507,
      "step": 2170
    },
    {
      "epoch": 2.6488456865127583,
      "grad_norm": 0.6192443370819092,
      "learning_rate": 0.0003442857142857143,
      "loss": 0.0557,
      "step": 2180
    },
    {
      "epoch": 2.660996354799514,
      "grad_norm": 0.37867531180381775,
      "learning_rate": 0.0003435714285714286,
      "loss": 0.044,
      "step": 2190
    },
    {
      "epoch": 2.67314702308627,
      "grad_norm": 1.564804196357727,
      "learning_rate": 0.00034285714285714285,
      "loss": 0.0509,
      "step": 2200
    },
    {
      "epoch": 2.6852976913730258,
      "grad_norm": 0.519594132900238,
      "learning_rate": 0.00034214285714285716,
      "loss": 0.0516,
      "step": 2210
    },
    {
      "epoch": 2.697448359659781,
      "grad_norm": 0.5241551995277405,
      "learning_rate": 0.0003414285714285714,
      "loss": 0.0536,
      "step": 2220
    },
    {
      "epoch": 2.709599027946537,
      "grad_norm": 0.12573622167110443,
      "learning_rate": 0.0003407142857142857,
      "loss": 0.0536,
      "step": 2230
    },
    {
      "epoch": 2.7217496962332928,
      "grad_norm": 4.363798141479492,
      "learning_rate": 0.00034,
      "loss": 0.0594,
      "step": 2240
    },
    {
      "epoch": 2.7339003645200486,
      "grad_norm": 0.9047567248344421,
      "learning_rate": 0.00033928571428571433,
      "loss": 0.0499,
      "step": 2250
    },
    {
      "epoch": 2.7460510328068044,
      "grad_norm": 0.1938554346561432,
      "learning_rate": 0.0003385714285714286,
      "loss": 0.0562,
      "step": 2260
    },
    {
      "epoch": 2.75820170109356,
      "grad_norm": 1.7113103866577148,
      "learning_rate": 0.00033785714285714284,
      "loss": 0.0484,
      "step": 2270
    },
    {
      "epoch": 2.770352369380316,
      "grad_norm": 0.27446141839027405,
      "learning_rate": 0.00033714285714285714,
      "loss": 0.0749,
      "step": 2280
    },
    {
      "epoch": 2.782503037667072,
      "grad_norm": 0.8570758700370789,
      "learning_rate": 0.0003364285714285714,
      "loss": 0.0574,
      "step": 2290
    },
    {
      "epoch": 2.7946537059538272,
      "grad_norm": 2.07255482673645,
      "learning_rate": 0.0003357142857142857,
      "loss": 0.0515,
      "step": 2300
    },
    {
      "epoch": 2.806804374240583,
      "grad_norm": 1.1127160787582397,
      "learning_rate": 0.000335,
      "loss": 0.0469,
      "step": 2310
    },
    {
      "epoch": 2.818955042527339,
      "grad_norm": 1.6176971197128296,
      "learning_rate": 0.0003342857142857143,
      "loss": 0.062,
      "step": 2320
    },
    {
      "epoch": 2.8311057108140947,
      "grad_norm": 0.6257057785987854,
      "learning_rate": 0.00033357142857142857,
      "loss": 0.0549,
      "step": 2330
    },
    {
      "epoch": 2.8432563791008505,
      "grad_norm": 0.1647716760635376,
      "learning_rate": 0.0003328571428571429,
      "loss": 0.045,
      "step": 2340
    },
    {
      "epoch": 2.8554070473876063,
      "grad_norm": 1.5868488550186157,
      "learning_rate": 0.00033214285714285713,
      "loss": 0.0547,
      "step": 2350
    },
    {
      "epoch": 2.867557715674362,
      "grad_norm": 0.5387072563171387,
      "learning_rate": 0.00033142857142857144,
      "loss": 0.0538,
      "step": 2360
    },
    {
      "epoch": 2.879708383961118,
      "grad_norm": 0.5896640419960022,
      "learning_rate": 0.00033071428571428575,
      "loss": 0.0345,
      "step": 2370
    },
    {
      "epoch": 2.8918590522478738,
      "grad_norm": 0.40853914618492126,
      "learning_rate": 0.00033,
      "loss": 0.0573,
      "step": 2380
    },
    {
      "epoch": 2.9040097205346296,
      "grad_norm": 0.5865805149078369,
      "learning_rate": 0.0003292857142857143,
      "loss": 0.0696,
      "step": 2390
    },
    {
      "epoch": 2.9161603888213854,
      "grad_norm": 0.7174373865127563,
      "learning_rate": 0.00032857142857142856,
      "loss": 0.0547,
      "step": 2400
    },
    {
      "epoch": 2.928311057108141,
      "grad_norm": 0.5978330969810486,
      "learning_rate": 0.00032785714285714287,
      "loss": 0.0504,
      "step": 2410
    },
    {
      "epoch": 2.9404617253948966,
      "grad_norm": 1.8445724248886108,
      "learning_rate": 0.0003271428571428571,
      "loss": 0.0552,
      "step": 2420
    },
    {
      "epoch": 2.9526123936816524,
      "grad_norm": 0.1438770443201065,
      "learning_rate": 0.0003264285714285714,
      "loss": 0.0432,
      "step": 2430
    },
    {
      "epoch": 2.964763061968408,
      "grad_norm": 0.26711493730545044,
      "learning_rate": 0.00032571428571428573,
      "loss": 0.0591,
      "step": 2440
    },
    {
      "epoch": 2.976913730255164,
      "grad_norm": 1.151458740234375,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.0539,
      "step": 2450
    },
    {
      "epoch": 2.98906439854192,
      "grad_norm": 0.12995855510234833,
      "learning_rate": 0.0003242857142857143,
      "loss": 0.0616,
      "step": 2460
    },
    {
      "epoch": 3.0012150668286757,
      "grad_norm": 0.04442540928721428,
      "learning_rate": 0.0003235714285714286,
      "loss": 0.0421,
      "step": 2470
    },
    {
      "epoch": 3.0133657351154315,
      "grad_norm": 0.8279756307601929,
      "learning_rate": 0.00032285714285714285,
      "loss": 0.0464,
      "step": 2480
    },
    {
      "epoch": 3.0255164034021873,
      "grad_norm": 0.6063413023948669,
      "learning_rate": 0.0003221428571428571,
      "loss": 0.0446,
      "step": 2490
    },
    {
      "epoch": 3.0376670716889427,
      "grad_norm": 1.080763816833496,
      "learning_rate": 0.00032142857142857147,
      "loss": 0.0455,
      "step": 2500
    },
    {
      "epoch": 3.0498177399756985,
      "grad_norm": 0.126795694231987,
      "learning_rate": 0.0003207142857142857,
      "loss": 0.0441,
      "step": 2510
    },
    {
      "epoch": 3.0619684082624543,
      "grad_norm": 0.1429079920053482,
      "learning_rate": 0.00032,
      "loss": 0.0442,
      "step": 2520
    },
    {
      "epoch": 3.07411907654921,
      "grad_norm": 0.11144319921731949,
      "learning_rate": 0.0003192857142857143,
      "loss": 0.04,
      "step": 2530
    },
    {
      "epoch": 3.086269744835966,
      "grad_norm": 2.1993227005004883,
      "learning_rate": 0.0003185714285714286,
      "loss": 0.0455,
      "step": 2540
    },
    {
      "epoch": 3.0984204131227218,
      "grad_norm": 1.0010472536087036,
      "learning_rate": 0.00031785714285714284,
      "loss": 0.0395,
      "step": 2550
    },
    {
      "epoch": 3.1105710814094776,
      "grad_norm": 0.3801601231098175,
      "learning_rate": 0.00031714285714285715,
      "loss": 0.0464,
      "step": 2560
    },
    {
      "epoch": 3.1227217496962334,
      "grad_norm": 0.26782840490341187,
      "learning_rate": 0.00031642857142857145,
      "loss": 0.0459,
      "step": 2570
    },
    {
      "epoch": 3.134872417982989,
      "grad_norm": 0.5130158066749573,
      "learning_rate": 0.0003157142857142857,
      "loss": 0.0531,
      "step": 2580
    },
    {
      "epoch": 3.147023086269745,
      "grad_norm": 0.6296288967132568,
      "learning_rate": 0.000315,
      "loss": 0.0481,
      "step": 2590
    },
    {
      "epoch": 3.1591737545565004,
      "grad_norm": 0.3450931906700134,
      "learning_rate": 0.00031428571428571427,
      "loss": 0.0364,
      "step": 2600
    },
    {
      "epoch": 3.171324422843256,
      "grad_norm": 0.6908490657806396,
      "learning_rate": 0.0003135714285714286,
      "loss": 0.0461,
      "step": 2610
    },
    {
      "epoch": 3.183475091130012,
      "grad_norm": 0.14973227679729462,
      "learning_rate": 0.0003128571428571428,
      "loss": 0.0474,
      "step": 2620
    },
    {
      "epoch": 3.195625759416768,
      "grad_norm": 0.7948483228683472,
      "learning_rate": 0.0003121428571428572,
      "loss": 0.0424,
      "step": 2630
    },
    {
      "epoch": 3.2077764277035237,
      "grad_norm": 0.5475319027900696,
      "learning_rate": 0.00031142857142857144,
      "loss": 0.0503,
      "step": 2640
    },
    {
      "epoch": 3.2199270959902795,
      "grad_norm": 0.31710198521614075,
      "learning_rate": 0.00031071428571428575,
      "loss": 0.052,
      "step": 2650
    },
    {
      "epoch": 3.2320777642770353,
      "grad_norm": 0.1918763369321823,
      "learning_rate": 0.00031,
      "loss": 0.0317,
      "step": 2660
    },
    {
      "epoch": 3.244228432563791,
      "grad_norm": 0.8486474752426147,
      "learning_rate": 0.0003092857142857143,
      "loss": 0.0461,
      "step": 2670
    },
    {
      "epoch": 3.256379100850547,
      "grad_norm": 0.6400941610336304,
      "learning_rate": 0.00030857142857142856,
      "loss": 0.0423,
      "step": 2680
    },
    {
      "epoch": 3.2685297691373023,
      "grad_norm": 1.3477611541748047,
      "learning_rate": 0.00030785714285714287,
      "loss": 0.046,
      "step": 2690
    },
    {
      "epoch": 3.280680437424058,
      "grad_norm": 0.7635979056358337,
      "learning_rate": 0.0003071428571428572,
      "loss": 0.0543,
      "step": 2700
    },
    {
      "epoch": 3.292831105710814,
      "grad_norm": 0.49295175075531006,
      "learning_rate": 0.0003064285714285714,
      "loss": 0.0456,
      "step": 2710
    },
    {
      "epoch": 3.3049817739975698,
      "grad_norm": 0.2723490297794342,
      "learning_rate": 0.00030571428571428573,
      "loss": 0.045,
      "step": 2720
    },
    {
      "epoch": 3.3171324422843256,
      "grad_norm": 0.03244459629058838,
      "learning_rate": 0.000305,
      "loss": 0.0435,
      "step": 2730
    },
    {
      "epoch": 3.3292831105710814,
      "grad_norm": 0.017746062949299812,
      "learning_rate": 0.0003042857142857143,
      "loss": 0.0439,
      "step": 2740
    },
    {
      "epoch": 3.341433778857837,
      "grad_norm": 0.0868876576423645,
      "learning_rate": 0.00030357142857142855,
      "loss": 0.0562,
      "step": 2750
    },
    {
      "epoch": 3.353584447144593,
      "grad_norm": 0.08396173268556595,
      "learning_rate": 0.0003028571428571429,
      "loss": 0.0513,
      "step": 2760
    },
    {
      "epoch": 3.365735115431349,
      "grad_norm": 0.2962663471698761,
      "learning_rate": 0.00030214285714285716,
      "loss": 0.0452,
      "step": 2770
    },
    {
      "epoch": 3.3778857837181047,
      "grad_norm": 0.05815223231911659,
      "learning_rate": 0.0003014285714285714,
      "loss": 0.0454,
      "step": 2780
    },
    {
      "epoch": 3.3900364520048605,
      "grad_norm": 0.3518851399421692,
      "learning_rate": 0.0003007142857142857,
      "loss": 0.0446,
      "step": 2790
    },
    {
      "epoch": 3.402187120291616,
      "grad_norm": 1.458078145980835,
      "learning_rate": 0.0003,
      "loss": 0.0385,
      "step": 2800
    },
    {
      "epoch": 3.4143377885783717,
      "grad_norm": 0.51297926902771,
      "learning_rate": 0.0002992857142857143,
      "loss": 0.0373,
      "step": 2810
    },
    {
      "epoch": 3.4264884568651275,
      "grad_norm": 0.1718902289867401,
      "learning_rate": 0.0002985714285714286,
      "loss": 0.0377,
      "step": 2820
    },
    {
      "epoch": 3.4386391251518833,
      "grad_norm": 0.19505880773067474,
      "learning_rate": 0.0002978571428571429,
      "loss": 0.0562,
      "step": 2830
    },
    {
      "epoch": 3.450789793438639,
      "grad_norm": 0.112308569252491,
      "learning_rate": 0.00029714285714285715,
      "loss": 0.046,
      "step": 2840
    },
    {
      "epoch": 3.462940461725395,
      "grad_norm": 1.1185766458511353,
      "learning_rate": 0.00029642857142857145,
      "loss": 0.0363,
      "step": 2850
    },
    {
      "epoch": 3.4750911300121508,
      "grad_norm": 0.4809128940105438,
      "learning_rate": 0.0002957142857142857,
      "loss": 0.034,
      "step": 2860
    },
    {
      "epoch": 3.4872417982989066,
      "grad_norm": 0.9565616846084595,
      "learning_rate": 0.000295,
      "loss": 0.0439,
      "step": 2870
    },
    {
      "epoch": 3.4993924665856624,
      "grad_norm": 1.5561318397521973,
      "learning_rate": 0.00029428571428571427,
      "loss": 0.0447,
      "step": 2880
    },
    {
      "epoch": 3.5115431348724178,
      "grad_norm": 0.4648680090904236,
      "learning_rate": 0.0002935714285714286,
      "loss": 0.0452,
      "step": 2890
    },
    {
      "epoch": 3.5236938031591736,
      "grad_norm": 0.008362866938114166,
      "learning_rate": 0.0002928571428571429,
      "loss": 0.0458,
      "step": 2900
    },
    {
      "epoch": 3.5358444714459294,
      "grad_norm": 0.39550653100013733,
      "learning_rate": 0.00029214285714285713,
      "loss": 0.0481,
      "step": 2910
    },
    {
      "epoch": 3.547995139732685,
      "grad_norm": 0.023752877488732338,
      "learning_rate": 0.00029142857142857144,
      "loss": 0.0467,
      "step": 2920
    },
    {
      "epoch": 3.560145808019441,
      "grad_norm": 1.0925759077072144,
      "learning_rate": 0.0002907142857142857,
      "loss": 0.039,
      "step": 2930
    },
    {
      "epoch": 3.572296476306197,
      "grad_norm": 1.2317790985107422,
      "learning_rate": 0.00029,
      "loss": 0.055,
      "step": 2940
    },
    {
      "epoch": 3.5844471445929527,
      "grad_norm": 0.3340894281864166,
      "learning_rate": 0.0002892857142857143,
      "loss": 0.0544,
      "step": 2950
    },
    {
      "epoch": 3.5965978128797085,
      "grad_norm": 0.10229022800922394,
      "learning_rate": 0.0002885714285714286,
      "loss": 0.0353,
      "step": 2960
    },
    {
      "epoch": 3.6087484811664643,
      "grad_norm": 0.36616140604019165,
      "learning_rate": 0.00028785714285714287,
      "loss": 0.0508,
      "step": 2970
    },
    {
      "epoch": 3.62089914945322,
      "grad_norm": 0.12234801799058914,
      "learning_rate": 0.0002871428571428572,
      "loss": 0.0376,
      "step": 2980
    },
    {
      "epoch": 3.633049817739976,
      "grad_norm": 0.8685138821601868,
      "learning_rate": 0.00028642857142857143,
      "loss": 0.0542,
      "step": 2990
    },
    {
      "epoch": 3.6452004860267317,
      "grad_norm": 0.20203937590122223,
      "learning_rate": 0.0002857142857142857,
      "loss": 0.0361,
      "step": 3000
    },
    {
      "epoch": 3.657351154313487,
      "grad_norm": 0.7172621488571167,
      "learning_rate": 0.000285,
      "loss": 0.0395,
      "step": 3010
    },
    {
      "epoch": 3.669501822600243,
      "grad_norm": 0.35533764958381653,
      "learning_rate": 0.0002842857142857143,
      "loss": 0.044,
      "step": 3020
    },
    {
      "epoch": 3.6816524908869988,
      "grad_norm": 0.04991596192121506,
      "learning_rate": 0.0002835714285714286,
      "loss": 0.0375,
      "step": 3030
    },
    {
      "epoch": 3.6938031591737546,
      "grad_norm": 0.21895116567611694,
      "learning_rate": 0.00028285714285714286,
      "loss": 0.0461,
      "step": 3040
    },
    {
      "epoch": 3.7059538274605104,
      "grad_norm": 0.44794148206710815,
      "learning_rate": 0.00028214285714285716,
      "loss": 0.0382,
      "step": 3050
    },
    {
      "epoch": 3.718104495747266,
      "grad_norm": 1.1270569562911987,
      "learning_rate": 0.0002814285714285714,
      "loss": 0.0555,
      "step": 3060
    },
    {
      "epoch": 3.730255164034022,
      "grad_norm": 0.0978773832321167,
      "learning_rate": 0.0002807142857142857,
      "loss": 0.0531,
      "step": 3070
    },
    {
      "epoch": 3.7424058323207774,
      "grad_norm": 0.26171258091926575,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.0511,
      "step": 3080
    },
    {
      "epoch": 3.754556500607533,
      "grad_norm": 0.05664721503853798,
      "learning_rate": 0.0002792857142857143,
      "loss": 0.0344,
      "step": 3090
    },
    {
      "epoch": 3.766707168894289,
      "grad_norm": 0.27316224575042725,
      "learning_rate": 0.0002785714285714286,
      "loss": 0.0411,
      "step": 3100
    },
    {
      "epoch": 3.778857837181045,
      "grad_norm": 0.3155771493911743,
      "learning_rate": 0.00027785714285714284,
      "loss": 0.0423,
      "step": 3110
    },
    {
      "epoch": 3.7910085054678007,
      "grad_norm": 0.6879211068153381,
      "learning_rate": 0.00027714285714285715,
      "loss": 0.0499,
      "step": 3120
    },
    {
      "epoch": 3.8031591737545565,
      "grad_norm": 1.9002649784088135,
      "learning_rate": 0.0002764285714285714,
      "loss": 0.0446,
      "step": 3130
    },
    {
      "epoch": 3.8153098420413123,
      "grad_norm": 0.16063068807125092,
      "learning_rate": 0.0002757142857142857,
      "loss": 0.049,
      "step": 3140
    },
    {
      "epoch": 3.827460510328068,
      "grad_norm": 0.29784929752349854,
      "learning_rate": 0.000275,
      "loss": 0.0687,
      "step": 3150
    },
    {
      "epoch": 3.839611178614824,
      "grad_norm": 0.4816698729991913,
      "learning_rate": 0.0002742857142857143,
      "loss": 0.048,
      "step": 3160
    },
    {
      "epoch": 3.8517618469015797,
      "grad_norm": 0.036487024277448654,
      "learning_rate": 0.0002735714285714286,
      "loss": 0.0378,
      "step": 3170
    },
    {
      "epoch": 3.8639125151883356,
      "grad_norm": 0.4480322301387787,
      "learning_rate": 0.0002728571428571429,
      "loss": 0.0456,
      "step": 3180
    },
    {
      "epoch": 3.8760631834750914,
      "grad_norm": 0.47501736879348755,
      "learning_rate": 0.00027214285714285714,
      "loss": 0.0414,
      "step": 3190
    },
    {
      "epoch": 3.8882138517618468,
      "grad_norm": 0.016538415104150772,
      "learning_rate": 0.0002714285714285714,
      "loss": 0.0628,
      "step": 3200
    },
    {
      "epoch": 3.9003645200486026,
      "grad_norm": 0.14381363987922668,
      "learning_rate": 0.00027071428571428575,
      "loss": 0.0401,
      "step": 3210
    },
    {
      "epoch": 3.9125151883353584,
      "grad_norm": 0.7730980515480042,
      "learning_rate": 0.00027,
      "loss": 0.0522,
      "step": 3220
    },
    {
      "epoch": 3.924665856622114,
      "grad_norm": 0.3100266754627228,
      "learning_rate": 0.0002692857142857143,
      "loss": 0.0515,
      "step": 3230
    },
    {
      "epoch": 3.93681652490887,
      "grad_norm": 3.0427238941192627,
      "learning_rate": 0.00026857142857142856,
      "loss": 0.0492,
      "step": 3240
    },
    {
      "epoch": 3.948967193195626,
      "grad_norm": 0.22813108563423157,
      "learning_rate": 0.00026785714285714287,
      "loss": 0.0445,
      "step": 3250
    },
    {
      "epoch": 3.9611178614823817,
      "grad_norm": 0.4883352518081665,
      "learning_rate": 0.0002671428571428571,
      "loss": 0.0425,
      "step": 3260
    },
    {
      "epoch": 3.973268529769137,
      "grad_norm": 1.553607702255249,
      "learning_rate": 0.00026642857142857143,
      "loss": 0.0463,
      "step": 3270
    },
    {
      "epoch": 3.985419198055893,
      "grad_norm": 2.1403560638427734,
      "learning_rate": 0.00026571428571428574,
      "loss": 0.0668,
      "step": 3280
    },
    {
      "epoch": 3.9975698663426487,
      "grad_norm": 1.2247841358184814,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.0457,
      "step": 3290
    },
    {
      "epoch": 4.0097205346294045,
      "grad_norm": 0.44232800602912903,
      "learning_rate": 0.0002642857142857143,
      "loss": 0.0412,
      "step": 3300
    },
    {
      "epoch": 4.02187120291616,
      "grad_norm": 0.007846874184906483,
      "learning_rate": 0.00026357142857142855,
      "loss": 0.0356,
      "step": 3310
    },
    {
      "epoch": 4.034021871202916,
      "grad_norm": 0.8733944892883301,
      "learning_rate": 0.00026285714285714286,
      "loss": 0.0382,
      "step": 3320
    },
    {
      "epoch": 4.046172539489672,
      "grad_norm": 0.35354578495025635,
      "learning_rate": 0.0002621428571428571,
      "loss": 0.0358,
      "step": 3330
    },
    {
      "epoch": 4.058323207776428,
      "grad_norm": 0.028912149369716644,
      "learning_rate": 0.00026142857142857147,
      "loss": 0.0364,
      "step": 3340
    },
    {
      "epoch": 4.070473876063184,
      "grad_norm": 0.020319437608122826,
      "learning_rate": 0.0002607142857142857,
      "loss": 0.0367,
      "step": 3350
    },
    {
      "epoch": 4.082624544349939,
      "grad_norm": 0.1736001968383789,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.0376,
      "step": 3360
    },
    {
      "epoch": 4.094775212636695,
      "grad_norm": 0.11668713390827179,
      "learning_rate": 0.0002592857142857143,
      "loss": 0.0389,
      "step": 3370
    },
    {
      "epoch": 4.106925880923451,
      "grad_norm": 0.02707722783088684,
      "learning_rate": 0.0002585714285714286,
      "loss": 0.0383,
      "step": 3380
    },
    {
      "epoch": 4.119076549210207,
      "grad_norm": 0.16055519878864288,
      "learning_rate": 0.00025785714285714284,
      "loss": 0.0403,
      "step": 3390
    },
    {
      "epoch": 4.131227217496963,
      "grad_norm": 0.9424710273742676,
      "learning_rate": 0.0002571428571428571,
      "loss": 0.0369,
      "step": 3400
    },
    {
      "epoch": 4.1433778857837185,
      "grad_norm": 0.4855208694934845,
      "learning_rate": 0.00025642857142857146,
      "loss": 0.0351,
      "step": 3410
    },
    {
      "epoch": 4.155528554070474,
      "grad_norm": 0.04811964929103851,
      "learning_rate": 0.0002557142857142857,
      "loss": 0.0492,
      "step": 3420
    },
    {
      "epoch": 4.167679222357229,
      "grad_norm": 0.11053694039583206,
      "learning_rate": 0.000255,
      "loss": 0.0486,
      "step": 3430
    },
    {
      "epoch": 4.179829890643985,
      "grad_norm": 0.14296765625476837,
      "learning_rate": 0.00025428571428571427,
      "loss": 0.0367,
      "step": 3440
    },
    {
      "epoch": 4.191980558930741,
      "grad_norm": 0.03013700805604458,
      "learning_rate": 0.0002535714285714286,
      "loss": 0.0473,
      "step": 3450
    },
    {
      "epoch": 4.204131227217497,
      "grad_norm": 0.12202100455760956,
      "learning_rate": 0.00025285714285714283,
      "loss": 0.0416,
      "step": 3460
    },
    {
      "epoch": 4.2162818955042525,
      "grad_norm": 0.3624640107154846,
      "learning_rate": 0.0002521428571428572,
      "loss": 0.0464,
      "step": 3470
    },
    {
      "epoch": 4.228432563791008,
      "grad_norm": 0.17073236405849457,
      "learning_rate": 0.00025142857142857145,
      "loss": 0.0356,
      "step": 3480
    },
    {
      "epoch": 4.240583232077764,
      "grad_norm": 1.0095064640045166,
      "learning_rate": 0.00025071428571428575,
      "loss": 0.0429,
      "step": 3490
    },
    {
      "epoch": 4.25273390036452,
      "grad_norm": 0.5233405232429504,
      "learning_rate": 0.00025,
      "loss": 0.0543,
      "step": 3500
    },
    {
      "epoch": 4.264884568651276,
      "grad_norm": 0.05832048878073692,
      "learning_rate": 0.00024928571428571426,
      "loss": 0.0329,
      "step": 3510
    },
    {
      "epoch": 4.277035236938032,
      "grad_norm": 1.5704299211502075,
      "learning_rate": 0.00024857142857142857,
      "loss": 0.0402,
      "step": 3520
    },
    {
      "epoch": 4.289185905224787,
      "grad_norm": 0.04126117378473282,
      "learning_rate": 0.00024785714285714287,
      "loss": 0.0415,
      "step": 3530
    },
    {
      "epoch": 4.301336573511543,
      "grad_norm": 0.12134592235088348,
      "learning_rate": 0.0002471428571428571,
      "loss": 0.0377,
      "step": 3540
    },
    {
      "epoch": 4.313487241798299,
      "grad_norm": 0.11598961800336838,
      "learning_rate": 0.00024642857142857143,
      "loss": 0.0415,
      "step": 3550
    },
    {
      "epoch": 4.325637910085055,
      "grad_norm": 0.17166991531848907,
      "learning_rate": 0.00024571428571428574,
      "loss": 0.0385,
      "step": 3560
    },
    {
      "epoch": 4.337788578371811,
      "grad_norm": 0.6456546187400818,
      "learning_rate": 0.000245,
      "loss": 0.0488,
      "step": 3570
    },
    {
      "epoch": 4.3499392466585665,
      "grad_norm": 0.09763014316558838,
      "learning_rate": 0.0002442857142857143,
      "loss": 0.0349,
      "step": 3580
    },
    {
      "epoch": 4.362089914945322,
      "grad_norm": 0.6965734362602234,
      "learning_rate": 0.00024357142857142858,
      "loss": 0.042,
      "step": 3590
    },
    {
      "epoch": 4.374240583232078,
      "grad_norm": 0.7118868827819824,
      "learning_rate": 0.00024285714285714286,
      "loss": 0.044,
      "step": 3600
    },
    {
      "epoch": 4.386391251518834,
      "grad_norm": 0.4677773118019104,
      "learning_rate": 0.00024214285714285714,
      "loss": 0.0439,
      "step": 3610
    },
    {
      "epoch": 4.39854191980559,
      "grad_norm": 0.2384738028049469,
      "learning_rate": 0.00024142857142857145,
      "loss": 0.04,
      "step": 3620
    },
    {
      "epoch": 4.4106925880923455,
      "grad_norm": 0.6120309829711914,
      "learning_rate": 0.00024071428571428573,
      "loss": 0.0446,
      "step": 3630
    },
    {
      "epoch": 4.4228432563791005,
      "grad_norm": 0.051943253725767136,
      "learning_rate": 0.00024,
      "loss": 0.0414,
      "step": 3640
    },
    {
      "epoch": 4.434993924665856,
      "grad_norm": 0.00571861956268549,
      "learning_rate": 0.0002392857142857143,
      "loss": 0.046,
      "step": 3650
    },
    {
      "epoch": 4.447144592952612,
      "grad_norm": 1.0525413751602173,
      "learning_rate": 0.00023857142857142857,
      "loss": 0.0424,
      "step": 3660
    },
    {
      "epoch": 4.459295261239368,
      "grad_norm": 0.2818974256515503,
      "learning_rate": 0.00023785714285714285,
      "loss": 0.0369,
      "step": 3670
    },
    {
      "epoch": 4.471445929526124,
      "grad_norm": 1.4397523403167725,
      "learning_rate": 0.00023714285714285715,
      "loss": 0.0367,
      "step": 3680
    },
    {
      "epoch": 4.48359659781288,
      "grad_norm": 1.8674367666244507,
      "learning_rate": 0.00023642857142857143,
      "loss": 0.0404,
      "step": 3690
    },
    {
      "epoch": 4.495747266099635,
      "grad_norm": 0.005959919188171625,
      "learning_rate": 0.0002357142857142857,
      "loss": 0.0396,
      "step": 3700
    },
    {
      "epoch": 4.507897934386391,
      "grad_norm": 0.07776443660259247,
      "learning_rate": 0.000235,
      "loss": 0.0401,
      "step": 3710
    },
    {
      "epoch": 4.520048602673147,
      "grad_norm": 0.4366494417190552,
      "learning_rate": 0.0002342857142857143,
      "loss": 0.0355,
      "step": 3720
    },
    {
      "epoch": 4.532199270959903,
      "grad_norm": 0.18751460313796997,
      "learning_rate": 0.00023357142857142858,
      "loss": 0.0372,
      "step": 3730
    },
    {
      "epoch": 4.544349939246659,
      "grad_norm": 0.1839497983455658,
      "learning_rate": 0.00023285714285714286,
      "loss": 0.0343,
      "step": 3740
    },
    {
      "epoch": 4.5565006075334145,
      "grad_norm": 0.40400466322898865,
      "learning_rate": 0.00023214285714285717,
      "loss": 0.0337,
      "step": 3750
    },
    {
      "epoch": 4.56865127582017,
      "grad_norm": 0.010554252192378044,
      "learning_rate": 0.00023142857142857142,
      "loss": 0.0398,
      "step": 3760
    },
    {
      "epoch": 4.580801944106926,
      "grad_norm": 0.08966360241174698,
      "learning_rate": 0.0002307142857142857,
      "loss": 0.0366,
      "step": 3770
    },
    {
      "epoch": 4.592952612393682,
      "grad_norm": 0.1081790179014206,
      "learning_rate": 0.00023,
      "loss": 0.0414,
      "step": 3780
    },
    {
      "epoch": 4.605103280680438,
      "grad_norm": 0.7421696186065674,
      "learning_rate": 0.0002292857142857143,
      "loss": 0.0342,
      "step": 3790
    },
    {
      "epoch": 4.6172539489671935,
      "grad_norm": 0.4804246425628662,
      "learning_rate": 0.00022857142857142857,
      "loss": 0.045,
      "step": 3800
    },
    {
      "epoch": 4.6294046172539485,
      "grad_norm": 0.7766379714012146,
      "learning_rate": 0.00022785714285714287,
      "loss": 0.0382,
      "step": 3810
    },
    {
      "epoch": 4.641555285540704,
      "grad_norm": 0.5800638198852539,
      "learning_rate": 0.00022714285714285715,
      "loss": 0.0437,
      "step": 3820
    },
    {
      "epoch": 4.65370595382746,
      "grad_norm": 0.2615547478199005,
      "learning_rate": 0.00022642857142857143,
      "loss": 0.0487,
      "step": 3830
    },
    {
      "epoch": 4.665856622114216,
      "grad_norm": 0.13549861311912537,
      "learning_rate": 0.00022571428571428571,
      "loss": 0.0444,
      "step": 3840
    },
    {
      "epoch": 4.678007290400972,
      "grad_norm": 0.05991031602025032,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.037,
      "step": 3850
    },
    {
      "epoch": 4.690157958687728,
      "grad_norm": 0.7834069728851318,
      "learning_rate": 0.0002242857142857143,
      "loss": 0.0401,
      "step": 3860
    },
    {
      "epoch": 4.702308626974483,
      "grad_norm": 0.11457184702157974,
      "learning_rate": 0.00022357142857142855,
      "loss": 0.0506,
      "step": 3870
    },
    {
      "epoch": 4.714459295261239,
      "grad_norm": 0.016247093677520752,
      "learning_rate": 0.00022285714285714286,
      "loss": 0.0336,
      "step": 3880
    },
    {
      "epoch": 4.726609963547995,
      "grad_norm": 0.47498658299446106,
      "learning_rate": 0.00022214285714285714,
      "loss": 0.0312,
      "step": 3890
    },
    {
      "epoch": 4.738760631834751,
      "grad_norm": 0.37143442034721375,
      "learning_rate": 0.00022142857142857142,
      "loss": 0.043,
      "step": 3900
    },
    {
      "epoch": 4.750911300121507,
      "grad_norm": 0.7304936647415161,
      "learning_rate": 0.00022071428571428573,
      "loss": 0.0527,
      "step": 3910
    },
    {
      "epoch": 4.7630619684082625,
      "grad_norm": 0.23569060862064362,
      "learning_rate": 0.00022,
      "loss": 0.0327,
      "step": 3920
    },
    {
      "epoch": 4.775212636695018,
      "grad_norm": 0.07425455003976822,
      "learning_rate": 0.0002192857142857143,
      "loss": 0.0346,
      "step": 3930
    },
    {
      "epoch": 4.787363304981774,
      "grad_norm": 0.30047929286956787,
      "learning_rate": 0.0002185714285714286,
      "loss": 0.0414,
      "step": 3940
    },
    {
      "epoch": 4.79951397326853,
      "grad_norm": 0.5396772623062134,
      "learning_rate": 0.00021785714285714287,
      "loss": 0.0427,
      "step": 3950
    },
    {
      "epoch": 4.811664641555286,
      "grad_norm": 0.2732289135456085,
      "learning_rate": 0.00021714285714285715,
      "loss": 0.0446,
      "step": 3960
    },
    {
      "epoch": 4.8238153098420415,
      "grad_norm": 0.25237125158309937,
      "learning_rate": 0.00021642857142857143,
      "loss": 0.0366,
      "step": 3970
    },
    {
      "epoch": 4.835965978128797,
      "grad_norm": 1.1115623712539673,
      "learning_rate": 0.00021571428571428571,
      "loss": 0.0386,
      "step": 3980
    },
    {
      "epoch": 4.848116646415553,
      "grad_norm": 0.12012765556573868,
      "learning_rate": 0.000215,
      "loss": 0.0366,
      "step": 3990
    },
    {
      "epoch": 4.860267314702309,
      "grad_norm": 0.11101148277521133,
      "learning_rate": 0.00021428571428571427,
      "loss": 0.0381,
      "step": 4000
    }
  ],
  "logging_steps": 10,
  "max_steps": 7000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.746111581324621e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
