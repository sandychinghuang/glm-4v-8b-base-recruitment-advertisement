{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.9100684261974585,
  "eval_steps": 7000,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009775171065493646,
      "grad_norm": 0.3469060957431793,
      "learning_rate": 0.0004992857142857143,
      "loss": 0.2048,
      "step": 10
    },
    {
      "epoch": 0.019550342130987292,
      "grad_norm": 1.2448267936706543,
      "learning_rate": 0.0004985714285714285,
      "loss": 0.1741,
      "step": 20
    },
    {
      "epoch": 0.02932551319648094,
      "grad_norm": 1.5454041957855225,
      "learning_rate": 0.0004978571428571429,
      "loss": 0.149,
      "step": 30
    },
    {
      "epoch": 0.039100684261974585,
      "grad_norm": 0.44008931517601013,
      "learning_rate": 0.0004971428571428571,
      "loss": 0.122,
      "step": 40
    },
    {
      "epoch": 0.04887585532746823,
      "grad_norm": 1.5372579097747803,
      "learning_rate": 0.0004964285714285715,
      "loss": 0.1222,
      "step": 50
    },
    {
      "epoch": 0.05865102639296188,
      "grad_norm": 1.1775696277618408,
      "learning_rate": 0.0004957142857142857,
      "loss": 0.1172,
      "step": 60
    },
    {
      "epoch": 0.06842619745845552,
      "grad_norm": 0.7003459930419922,
      "learning_rate": 0.000495,
      "loss": 0.0865,
      "step": 70
    },
    {
      "epoch": 0.07820136852394917,
      "grad_norm": 0.5310140252113342,
      "learning_rate": 0.0004942857142857143,
      "loss": 0.1184,
      "step": 80
    },
    {
      "epoch": 0.08797653958944282,
      "grad_norm": 0.5407089591026306,
      "learning_rate": 0.0004935714285714286,
      "loss": 0.0847,
      "step": 90
    },
    {
      "epoch": 0.09775171065493646,
      "grad_norm": 1.1448665857315063,
      "learning_rate": 0.0004928571428571429,
      "loss": 0.123,
      "step": 100
    },
    {
      "epoch": 0.10752688172043011,
      "grad_norm": 0.45457252860069275,
      "learning_rate": 0.0004921428571428571,
      "loss": 0.1027,
      "step": 110
    },
    {
      "epoch": 0.11730205278592376,
      "grad_norm": 0.4705680310726166,
      "learning_rate": 0.0004914285714285715,
      "loss": 0.0727,
      "step": 120
    },
    {
      "epoch": 0.1270772238514174,
      "grad_norm": 2.8475587368011475,
      "learning_rate": 0.0004907142857142857,
      "loss": 0.0547,
      "step": 130
    },
    {
      "epoch": 0.13685239491691104,
      "grad_norm": 0.9157189726829529,
      "learning_rate": 0.00049,
      "loss": 0.0821,
      "step": 140
    },
    {
      "epoch": 0.1466275659824047,
      "grad_norm": 1.706381916999817,
      "learning_rate": 0.0004892857142857142,
      "loss": 0.1008,
      "step": 150
    },
    {
      "epoch": 0.15640273704789834,
      "grad_norm": 1.1435818672180176,
      "learning_rate": 0.0004885714285714286,
      "loss": 0.1638,
      "step": 160
    },
    {
      "epoch": 0.16617790811339198,
      "grad_norm": 0.6264650821685791,
      "learning_rate": 0.0004878571428571429,
      "loss": 0.0833,
      "step": 170
    },
    {
      "epoch": 0.17595307917888564,
      "grad_norm": 0.9087602496147156,
      "learning_rate": 0.00048714285714285716,
      "loss": 0.087,
      "step": 180
    },
    {
      "epoch": 0.18572825024437928,
      "grad_norm": 0.8254212737083435,
      "learning_rate": 0.00048642857142857147,
      "loss": 0.0904,
      "step": 190
    },
    {
      "epoch": 0.19550342130987292,
      "grad_norm": 0.4531248211860657,
      "learning_rate": 0.0004857142857142857,
      "loss": 0.0884,
      "step": 200
    },
    {
      "epoch": 0.20527859237536658,
      "grad_norm": 0.6017314791679382,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.0908,
      "step": 210
    },
    {
      "epoch": 0.21505376344086022,
      "grad_norm": 1.278093695640564,
      "learning_rate": 0.0004842857142857143,
      "loss": 0.0869,
      "step": 220
    },
    {
      "epoch": 0.22482893450635386,
      "grad_norm": 0.838141143321991,
      "learning_rate": 0.0004835714285714286,
      "loss": 0.0857,
      "step": 230
    },
    {
      "epoch": 0.23460410557184752,
      "grad_norm": 0.5034255981445312,
      "learning_rate": 0.0004828571428571429,
      "loss": 0.0801,
      "step": 240
    },
    {
      "epoch": 0.24437927663734116,
      "grad_norm": 0.20288042724132538,
      "learning_rate": 0.00048214285714285715,
      "loss": 0.0875,
      "step": 250
    },
    {
      "epoch": 0.2541544477028348,
      "grad_norm": 0.8731309175491333,
      "learning_rate": 0.00048142857142857145,
      "loss": 0.1275,
      "step": 260
    },
    {
      "epoch": 0.26392961876832843,
      "grad_norm": 0.3568805158138275,
      "learning_rate": 0.0004807142857142857,
      "loss": 0.0686,
      "step": 270
    },
    {
      "epoch": 0.27370478983382207,
      "grad_norm": 0.3177434206008911,
      "learning_rate": 0.00048,
      "loss": 0.0759,
      "step": 280
    },
    {
      "epoch": 0.28347996089931576,
      "grad_norm": 1.201444387435913,
      "learning_rate": 0.00047928571428571427,
      "loss": 0.0976,
      "step": 290
    },
    {
      "epoch": 0.2932551319648094,
      "grad_norm": 1.480231523513794,
      "learning_rate": 0.0004785714285714286,
      "loss": 0.0931,
      "step": 300
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 0.4570973813533783,
      "learning_rate": 0.0004778571428571429,
      "loss": 0.1131,
      "step": 310
    },
    {
      "epoch": 0.3128054740957967,
      "grad_norm": 0.23703110218048096,
      "learning_rate": 0.00047714285714285713,
      "loss": 0.089,
      "step": 320
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 0.5978885293006897,
      "learning_rate": 0.00047642857142857144,
      "loss": 0.1042,
      "step": 330
    },
    {
      "epoch": 0.33235581622678395,
      "grad_norm": 0.44651320576667786,
      "learning_rate": 0.0004757142857142857,
      "loss": 0.0913,
      "step": 340
    },
    {
      "epoch": 0.3421309872922776,
      "grad_norm": 1.0341466665267944,
      "learning_rate": 0.000475,
      "loss": 0.1061,
      "step": 350
    },
    {
      "epoch": 0.3519061583577713,
      "grad_norm": 0.3216857314109802,
      "learning_rate": 0.0004742857142857143,
      "loss": 0.0893,
      "step": 360
    },
    {
      "epoch": 0.3616813294232649,
      "grad_norm": 0.480277419090271,
      "learning_rate": 0.0004735714285714286,
      "loss": 0.0844,
      "step": 370
    },
    {
      "epoch": 0.37145650048875856,
      "grad_norm": 0.538446307182312,
      "learning_rate": 0.00047285714285714287,
      "loss": 0.08,
      "step": 380
    },
    {
      "epoch": 0.3812316715542522,
      "grad_norm": 0.6838845014572144,
      "learning_rate": 0.0004721428571428572,
      "loss": 0.0765,
      "step": 390
    },
    {
      "epoch": 0.39100684261974583,
      "grad_norm": 2.2496840953826904,
      "learning_rate": 0.0004714285714285714,
      "loss": 0.1017,
      "step": 400
    },
    {
      "epoch": 0.40078201368523947,
      "grad_norm": 0.4504598379135132,
      "learning_rate": 0.00047071428571428573,
      "loss": 0.1014,
      "step": 410
    },
    {
      "epoch": 0.41055718475073316,
      "grad_norm": 0.25450780987739563,
      "learning_rate": 0.00047,
      "loss": 0.0987,
      "step": 420
    },
    {
      "epoch": 0.4203323558162268,
      "grad_norm": 0.6321038603782654,
      "learning_rate": 0.0004692857142857143,
      "loss": 0.0743,
      "step": 430
    },
    {
      "epoch": 0.43010752688172044,
      "grad_norm": 0.7286423444747925,
      "learning_rate": 0.0004685714285714286,
      "loss": 0.0892,
      "step": 440
    },
    {
      "epoch": 0.4398826979472141,
      "grad_norm": 1.3339258432388306,
      "learning_rate": 0.00046785714285714285,
      "loss": 0.0655,
      "step": 450
    },
    {
      "epoch": 0.4496578690127077,
      "grad_norm": 0.5582637190818787,
      "learning_rate": 0.00046714285714285716,
      "loss": 0.0906,
      "step": 460
    },
    {
      "epoch": 0.45943304007820135,
      "grad_norm": 0.28045961260795593,
      "learning_rate": 0.0004664285714285714,
      "loss": 0.0875,
      "step": 470
    },
    {
      "epoch": 0.46920821114369504,
      "grad_norm": 1.5164964199066162,
      "learning_rate": 0.0004657142857142857,
      "loss": 0.0937,
      "step": 480
    },
    {
      "epoch": 0.4789833822091887,
      "grad_norm": 2.1306722164154053,
      "learning_rate": 0.000465,
      "loss": 0.0958,
      "step": 490
    },
    {
      "epoch": 0.4887585532746823,
      "grad_norm": 1.1355559825897217,
      "learning_rate": 0.00046428571428571433,
      "loss": 0.0673,
      "step": 500
    },
    {
      "epoch": 0.49853372434017595,
      "grad_norm": 0.13243050873279572,
      "learning_rate": 0.0004635714285714286,
      "loss": 0.086,
      "step": 510
    },
    {
      "epoch": 0.5083088954056696,
      "grad_norm": 0.6101992130279541,
      "learning_rate": 0.00046285714285714284,
      "loss": 0.0656,
      "step": 520
    },
    {
      "epoch": 0.5180840664711632,
      "grad_norm": 0.1813661754131317,
      "learning_rate": 0.00046214285714285715,
      "loss": 0.0647,
      "step": 530
    },
    {
      "epoch": 0.5278592375366569,
      "grad_norm": 0.49659931659698486,
      "learning_rate": 0.0004614285714285714,
      "loss": 0.0802,
      "step": 540
    },
    {
      "epoch": 0.5376344086021505,
      "grad_norm": 0.3570685386657715,
      "learning_rate": 0.0004607142857142857,
      "loss": 0.0681,
      "step": 550
    },
    {
      "epoch": 0.5474095796676441,
      "grad_norm": 0.8942952752113342,
      "learning_rate": 0.00046,
      "loss": 0.0729,
      "step": 560
    },
    {
      "epoch": 0.5571847507331378,
      "grad_norm": 0.8302373290061951,
      "learning_rate": 0.0004592857142857143,
      "loss": 0.0946,
      "step": 570
    },
    {
      "epoch": 0.5669599217986315,
      "grad_norm": 2.06141996383667,
      "learning_rate": 0.0004585714285714286,
      "loss": 0.0884,
      "step": 580
    },
    {
      "epoch": 0.5767350928641252,
      "grad_norm": 1.322521448135376,
      "learning_rate": 0.0004578571428571429,
      "loss": 0.0751,
      "step": 590
    },
    {
      "epoch": 0.5865102639296188,
      "grad_norm": 0.966650664806366,
      "learning_rate": 0.00045714285714285713,
      "loss": 0.0637,
      "step": 600
    },
    {
      "epoch": 0.5962854349951124,
      "grad_norm": 0.3157223165035248,
      "learning_rate": 0.00045642857142857144,
      "loss": 0.0768,
      "step": 610
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 0.5705068111419678,
      "learning_rate": 0.00045571428571428575,
      "loss": 0.0575,
      "step": 620
    },
    {
      "epoch": 0.6158357771260997,
      "grad_norm": 0.1593351662158966,
      "learning_rate": 0.000455,
      "loss": 0.0579,
      "step": 630
    },
    {
      "epoch": 0.6256109481915934,
      "grad_norm": 0.165141299366951,
      "learning_rate": 0.0004542857142857143,
      "loss": 0.0806,
      "step": 640
    },
    {
      "epoch": 0.635386119257087,
      "grad_norm": 2.7679331302642822,
      "learning_rate": 0.00045357142857142856,
      "loss": 0.069,
      "step": 650
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.8572459816932678,
      "learning_rate": 0.00045285714285714287,
      "loss": 0.0674,
      "step": 660
    },
    {
      "epoch": 0.6549364613880743,
      "grad_norm": 1.1051924228668213,
      "learning_rate": 0.0004521428571428571,
      "loss": 0.0813,
      "step": 670
    },
    {
      "epoch": 0.6647116324535679,
      "grad_norm": 0.8907566070556641,
      "learning_rate": 0.00045142857142857143,
      "loss": 0.0665,
      "step": 680
    },
    {
      "epoch": 0.6744868035190615,
      "grad_norm": 0.9941390156745911,
      "learning_rate": 0.00045071428571428573,
      "loss": 0.081,
      "step": 690
    },
    {
      "epoch": 0.6842619745845552,
      "grad_norm": 0.8143631815910339,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.0961,
      "step": 700
    },
    {
      "epoch": 0.6940371456500489,
      "grad_norm": 3.228092908859253,
      "learning_rate": 0.0004492857142857143,
      "loss": 0.0852,
      "step": 710
    },
    {
      "epoch": 0.7038123167155426,
      "grad_norm": 0.8585466742515564,
      "learning_rate": 0.0004485714285714286,
      "loss": 0.0903,
      "step": 720
    },
    {
      "epoch": 0.7135874877810362,
      "grad_norm": 1.2185734510421753,
      "learning_rate": 0.00044785714285714285,
      "loss": 0.0936,
      "step": 730
    },
    {
      "epoch": 0.7233626588465298,
      "grad_norm": 0.7120552062988281,
      "learning_rate": 0.0004471428571428571,
      "loss": 0.0756,
      "step": 740
    },
    {
      "epoch": 0.7331378299120235,
      "grad_norm": 0.2752932608127594,
      "learning_rate": 0.00044642857142857147,
      "loss": 0.0924,
      "step": 750
    },
    {
      "epoch": 0.7429130009775171,
      "grad_norm": 0.8176473379135132,
      "learning_rate": 0.0004457142857142857,
      "loss": 0.0855,
      "step": 760
    },
    {
      "epoch": 0.7526881720430108,
      "grad_norm": 1.2494710683822632,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.0683,
      "step": 770
    },
    {
      "epoch": 0.7624633431085044,
      "grad_norm": 0.4383539855480194,
      "learning_rate": 0.0004442857142857143,
      "loss": 0.0876,
      "step": 780
    },
    {
      "epoch": 0.772238514173998,
      "grad_norm": 0.834686815738678,
      "learning_rate": 0.0004435714285714286,
      "loss": 0.0891,
      "step": 790
    },
    {
      "epoch": 0.7820136852394917,
      "grad_norm": 1.068468451499939,
      "learning_rate": 0.00044285714285714284,
      "loss": 0.047,
      "step": 800
    },
    {
      "epoch": 0.7917888563049853,
      "grad_norm": 0.09074034541845322,
      "learning_rate": 0.00044214285714285715,
      "loss": 0.1038,
      "step": 810
    },
    {
      "epoch": 0.8015640273704789,
      "grad_norm": 1.059008240699768,
      "learning_rate": 0.00044142857142857146,
      "loss": 0.0843,
      "step": 820
    },
    {
      "epoch": 0.8113391984359726,
      "grad_norm": 0.1763036549091339,
      "learning_rate": 0.0004407142857142857,
      "loss": 0.0723,
      "step": 830
    },
    {
      "epoch": 0.8211143695014663,
      "grad_norm": 0.7575662732124329,
      "learning_rate": 0.00044,
      "loss": 0.0607,
      "step": 840
    },
    {
      "epoch": 0.83088954056696,
      "grad_norm": 0.5261059999465942,
      "learning_rate": 0.00043928571428571427,
      "loss": 0.0782,
      "step": 850
    },
    {
      "epoch": 0.8406647116324536,
      "grad_norm": 1.67589271068573,
      "learning_rate": 0.0004385714285714286,
      "loss": 0.0702,
      "step": 860
    },
    {
      "epoch": 0.8504398826979472,
      "grad_norm": 0.3758578300476074,
      "learning_rate": 0.00043785714285714283,
      "loss": 0.0879,
      "step": 870
    },
    {
      "epoch": 0.8602150537634409,
      "grad_norm": 0.9435505270957947,
      "learning_rate": 0.0004371428571428572,
      "loss": 0.0839,
      "step": 880
    },
    {
      "epoch": 0.8699902248289345,
      "grad_norm": 0.5605663061141968,
      "learning_rate": 0.00043642857142857144,
      "loss": 0.1273,
      "step": 890
    },
    {
      "epoch": 0.8797653958944281,
      "grad_norm": 0.941618025302887,
      "learning_rate": 0.00043571428571428575,
      "loss": 0.0806,
      "step": 900
    },
    {
      "epoch": 0.8895405669599218,
      "grad_norm": 0.5825026631355286,
      "learning_rate": 0.000435,
      "loss": 0.0697,
      "step": 910
    },
    {
      "epoch": 0.8993157380254154,
      "grad_norm": 0.8815544843673706,
      "learning_rate": 0.0004342857142857143,
      "loss": 0.0769,
      "step": 920
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.759946882724762,
      "learning_rate": 0.00043357142857142856,
      "loss": 0.102,
      "step": 930
    },
    {
      "epoch": 0.9188660801564027,
      "grad_norm": 1.5912879705429077,
      "learning_rate": 0.00043285714285714287,
      "loss": 0.0747,
      "step": 940
    },
    {
      "epoch": 0.9286412512218963,
      "grad_norm": 1.4414554834365845,
      "learning_rate": 0.0004321428571428572,
      "loss": 0.0677,
      "step": 950
    },
    {
      "epoch": 0.9384164222873901,
      "grad_norm": 0.8526057004928589,
      "learning_rate": 0.00043142857142857143,
      "loss": 0.0586,
      "step": 960
    },
    {
      "epoch": 0.9481915933528837,
      "grad_norm": 0.4071994125843048,
      "learning_rate": 0.00043071428571428574,
      "loss": 0.0805,
      "step": 970
    },
    {
      "epoch": 0.9579667644183774,
      "grad_norm": 0.6289613842964172,
      "learning_rate": 0.00043,
      "loss": 0.0643,
      "step": 980
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.31807422637939453,
      "learning_rate": 0.0004292857142857143,
      "loss": 0.0702,
      "step": 990
    },
    {
      "epoch": 0.9775171065493646,
      "grad_norm": 0.571563184261322,
      "learning_rate": 0.00042857142857142855,
      "loss": 0.058,
      "step": 1000
    },
    {
      "epoch": 0.9872922776148583,
      "grad_norm": 1.6174979209899902,
      "learning_rate": 0.0004278571428571429,
      "loss": 0.0529,
      "step": 1010
    },
    {
      "epoch": 0.9970674486803519,
      "grad_norm": 0.9541440606117249,
      "learning_rate": 0.00042714285714285716,
      "loss": 0.09,
      "step": 1020
    },
    {
      "epoch": 1.0068426197458455,
      "grad_norm": 0.13823530077934265,
      "learning_rate": 0.0004264285714285714,
      "loss": 0.0771,
      "step": 1030
    },
    {
      "epoch": 1.0166177908113392,
      "grad_norm": 0.09458540380001068,
      "learning_rate": 0.0004257142857142857,
      "loss": 0.0419,
      "step": 1040
    },
    {
      "epoch": 1.0263929618768328,
      "grad_norm": 0.11264491081237793,
      "learning_rate": 0.000425,
      "loss": 0.0633,
      "step": 1050
    },
    {
      "epoch": 1.0361681329423265,
      "grad_norm": 0.4190598130226135,
      "learning_rate": 0.0004242857142857143,
      "loss": 0.0739,
      "step": 1060
    },
    {
      "epoch": 1.04594330400782,
      "grad_norm": 0.4703899323940277,
      "learning_rate": 0.0004235714285714286,
      "loss": 0.0588,
      "step": 1070
    },
    {
      "epoch": 1.0557184750733137,
      "grad_norm": 1.1091071367263794,
      "learning_rate": 0.0004228571428571429,
      "loss": 0.0652,
      "step": 1080
    },
    {
      "epoch": 1.0654936461388074,
      "grad_norm": 0.8818050026893616,
      "learning_rate": 0.00042214285714285715,
      "loss": 0.0503,
      "step": 1090
    },
    {
      "epoch": 1.075268817204301,
      "grad_norm": 0.24612732231616974,
      "learning_rate": 0.00042142857142857146,
      "loss": 0.0589,
      "step": 1100
    },
    {
      "epoch": 1.0850439882697946,
      "grad_norm": 0.40717580914497375,
      "learning_rate": 0.0004207142857142857,
      "loss": 0.076,
      "step": 1110
    },
    {
      "epoch": 1.0948191593352883,
      "grad_norm": 0.6788902878761292,
      "learning_rate": 0.00042,
      "loss": 0.0602,
      "step": 1120
    },
    {
      "epoch": 1.104594330400782,
      "grad_norm": 0.29109448194503784,
      "learning_rate": 0.00041928571428571427,
      "loss": 0.0602,
      "step": 1130
    },
    {
      "epoch": 1.1143695014662756,
      "grad_norm": 1.1122738122940063,
      "learning_rate": 0.0004185714285714286,
      "loss": 0.0675,
      "step": 1140
    },
    {
      "epoch": 1.1241446725317692,
      "grad_norm": 0.6416926383972168,
      "learning_rate": 0.0004178571428571429,
      "loss": 0.0868,
      "step": 1150
    },
    {
      "epoch": 1.1339198435972628,
      "grad_norm": 0.08051998168230057,
      "learning_rate": 0.00041714285714285714,
      "loss": 0.0631,
      "step": 1160
    },
    {
      "epoch": 1.1436950146627567,
      "grad_norm": 0.3274347484111786,
      "learning_rate": 0.00041642857142857144,
      "loss": 0.0694,
      "step": 1170
    },
    {
      "epoch": 1.1534701857282503,
      "grad_norm": 1.0060330629348755,
      "learning_rate": 0.0004157142857142857,
      "loss": 0.0659,
      "step": 1180
    },
    {
      "epoch": 1.163245356793744,
      "grad_norm": 0.04238384589552879,
      "learning_rate": 0.000415,
      "loss": 0.0679,
      "step": 1190
    },
    {
      "epoch": 1.1730205278592376,
      "grad_norm": 0.13005197048187256,
      "learning_rate": 0.0004142857142857143,
      "loss": 0.0771,
      "step": 1200
    },
    {
      "epoch": 1.1827956989247312,
      "grad_norm": 0.24410958588123322,
      "learning_rate": 0.0004135714285714286,
      "loss": 0.0622,
      "step": 1210
    },
    {
      "epoch": 1.1925708699902249,
      "grad_norm": 0.6887311339378357,
      "learning_rate": 0.00041285714285714287,
      "loss": 0.0682,
      "step": 1220
    },
    {
      "epoch": 1.2023460410557185,
      "grad_norm": 1.195708155632019,
      "learning_rate": 0.0004121428571428572,
      "loss": 0.0544,
      "step": 1230
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 0.6442456841468811,
      "learning_rate": 0.00041142857142857143,
      "loss": 0.0706,
      "step": 1240
    },
    {
      "epoch": 1.2218963831867058,
      "grad_norm": 0.5079416632652283,
      "learning_rate": 0.0004107142857142857,
      "loss": 0.0684,
      "step": 1250
    },
    {
      "epoch": 1.2316715542521994,
      "grad_norm": 0.34437981247901917,
      "learning_rate": 0.00041,
      "loss": 0.0521,
      "step": 1260
    },
    {
      "epoch": 1.241446725317693,
      "grad_norm": 0.6318445205688477,
      "learning_rate": 0.0004092857142857143,
      "loss": 0.0577,
      "step": 1270
    },
    {
      "epoch": 1.2512218963831867,
      "grad_norm": 0.2951236069202423,
      "learning_rate": 0.0004085714285714286,
      "loss": 0.0693,
      "step": 1280
    },
    {
      "epoch": 1.2609970674486803,
      "grad_norm": 0.597093939781189,
      "learning_rate": 0.00040785714285714286,
      "loss": 0.0735,
      "step": 1290
    },
    {
      "epoch": 1.270772238514174,
      "grad_norm": 0.8876598477363586,
      "learning_rate": 0.00040714285714285717,
      "loss": 0.0491,
      "step": 1300
    },
    {
      "epoch": 1.2805474095796676,
      "grad_norm": 0.10405831038951874,
      "learning_rate": 0.0004064285714285714,
      "loss": 0.0695,
      "step": 1310
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 1.4662463665008545,
      "learning_rate": 0.0004057142857142857,
      "loss": 0.0786,
      "step": 1320
    },
    {
      "epoch": 1.300097751710655,
      "grad_norm": 0.6633338928222656,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.0629,
      "step": 1330
    },
    {
      "epoch": 1.3098729227761485,
      "grad_norm": 0.43963199853897095,
      "learning_rate": 0.0004042857142857143,
      "loss": 0.0578,
      "step": 1340
    },
    {
      "epoch": 1.3196480938416422,
      "grad_norm": 0.5797938108444214,
      "learning_rate": 0.0004035714285714286,
      "loss": 0.054,
      "step": 1350
    },
    {
      "epoch": 1.3294232649071358,
      "grad_norm": 2.0726027488708496,
      "learning_rate": 0.00040285714285714285,
      "loss": 0.0665,
      "step": 1360
    },
    {
      "epoch": 1.3391984359726294,
      "grad_norm": 1.106705665588379,
      "learning_rate": 0.00040214285714285715,
      "loss": 0.0573,
      "step": 1370
    },
    {
      "epoch": 1.3489736070381233,
      "grad_norm": 0.9436753988265991,
      "learning_rate": 0.0004014285714285714,
      "loss": 0.0828,
      "step": 1380
    },
    {
      "epoch": 1.358748778103617,
      "grad_norm": 1.0515773296356201,
      "learning_rate": 0.0004007142857142857,
      "loss": 0.0662,
      "step": 1390
    },
    {
      "epoch": 1.3685239491691106,
      "grad_norm": 1.5081838369369507,
      "learning_rate": 0.0004,
      "loss": 0.0686,
      "step": 1400
    },
    {
      "epoch": 1.3782991202346042,
      "grad_norm": 0.5960513949394226,
      "learning_rate": 0.0003992857142857143,
      "loss": 0.0539,
      "step": 1410
    },
    {
      "epoch": 1.3880742913000979,
      "grad_norm": 0.9402570128440857,
      "learning_rate": 0.0003985714285714286,
      "loss": 0.0533,
      "step": 1420
    },
    {
      "epoch": 1.3978494623655915,
      "grad_norm": 0.8911082148551941,
      "learning_rate": 0.0003978571428571429,
      "loss": 0.0627,
      "step": 1430
    },
    {
      "epoch": 1.4076246334310851,
      "grad_norm": 0.23623524606227875,
      "learning_rate": 0.00039714285714285714,
      "loss": 0.0667,
      "step": 1440
    },
    {
      "epoch": 1.4173998044965788,
      "grad_norm": 0.12381911277770996,
      "learning_rate": 0.0003964285714285714,
      "loss": 0.0548,
      "step": 1450
    },
    {
      "epoch": 1.4271749755620724,
      "grad_norm": 1.2643682956695557,
      "learning_rate": 0.00039571428571428575,
      "loss": 0.0508,
      "step": 1460
    },
    {
      "epoch": 1.436950146627566,
      "grad_norm": 0.2026582658290863,
      "learning_rate": 0.000395,
      "loss": 0.0695,
      "step": 1470
    },
    {
      "epoch": 1.4467253176930597,
      "grad_norm": 0.03406001254916191,
      "learning_rate": 0.0003942857142857143,
      "loss": 0.0695,
      "step": 1480
    },
    {
      "epoch": 1.4565004887585533,
      "grad_norm": 0.8008965253829956,
      "learning_rate": 0.00039357142857142857,
      "loss": 0.069,
      "step": 1490
    },
    {
      "epoch": 1.466275659824047,
      "grad_norm": 0.7115922570228577,
      "learning_rate": 0.0003928571428571429,
      "loss": 0.0548,
      "step": 1500
    },
    {
      "epoch": 1.4760508308895406,
      "grad_norm": 0.7991302609443665,
      "learning_rate": 0.0003921428571428571,
      "loss": 0.0649,
      "step": 1510
    },
    {
      "epoch": 1.4858260019550342,
      "grad_norm": 0.7137575745582581,
      "learning_rate": 0.00039142857142857143,
      "loss": 0.0744,
      "step": 1520
    },
    {
      "epoch": 1.4956011730205279,
      "grad_norm": 1.041501760482788,
      "learning_rate": 0.00039071428571428574,
      "loss": 0.058,
      "step": 1530
    },
    {
      "epoch": 1.5053763440860215,
      "grad_norm": 0.2912409007549286,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.0484,
      "step": 1540
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 1.2585842609405518,
      "learning_rate": 0.0003892857142857143,
      "loss": 0.06,
      "step": 1550
    },
    {
      "epoch": 1.5249266862170088,
      "grad_norm": 1.39873468875885,
      "learning_rate": 0.00038857142857142855,
      "loss": 0.0529,
      "step": 1560
    },
    {
      "epoch": 1.5347018572825024,
      "grad_norm": 0.4640401005744934,
      "learning_rate": 0.00038785714285714286,
      "loss": 0.0498,
      "step": 1570
    },
    {
      "epoch": 1.544477028347996,
      "grad_norm": 0.6157101392745972,
      "learning_rate": 0.0003871428571428571,
      "loss": 0.0747,
      "step": 1580
    },
    {
      "epoch": 1.5542521994134897,
      "grad_norm": 0.8237465620040894,
      "learning_rate": 0.0003864285714285715,
      "loss": 0.0846,
      "step": 1590
    },
    {
      "epoch": 1.5640273704789833,
      "grad_norm": 0.6397078633308411,
      "learning_rate": 0.0003857142857142857,
      "loss": 0.0548,
      "step": 1600
    },
    {
      "epoch": 1.573802541544477,
      "grad_norm": 0.4192037880420685,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.0641,
      "step": 1610
    },
    {
      "epoch": 1.5835777126099706,
      "grad_norm": 0.12762236595153809,
      "learning_rate": 0.0003842857142857143,
      "loss": 0.0554,
      "step": 1620
    },
    {
      "epoch": 1.5933528836754642,
      "grad_norm": 1.7487986087799072,
      "learning_rate": 0.0003835714285714286,
      "loss": 0.0513,
      "step": 1630
    },
    {
      "epoch": 1.6031280547409579,
      "grad_norm": 0.04471452534198761,
      "learning_rate": 0.00038285714285714285,
      "loss": 0.054,
      "step": 1640
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.6129264235496521,
      "learning_rate": 0.0003821428571428571,
      "loss": 0.0484,
      "step": 1650
    },
    {
      "epoch": 1.6226783968719452,
      "grad_norm": 1.2288917303085327,
      "learning_rate": 0.00038142857142857146,
      "loss": 0.0537,
      "step": 1660
    },
    {
      "epoch": 1.6324535679374388,
      "grad_norm": 0.45567408204078674,
      "learning_rate": 0.0003807142857142857,
      "loss": 0.0479,
      "step": 1670
    },
    {
      "epoch": 1.6422287390029324,
      "grad_norm": 0.7346603274345398,
      "learning_rate": 0.00038,
      "loss": 0.0578,
      "step": 1680
    },
    {
      "epoch": 1.652003910068426,
      "grad_norm": 1.8224605321884155,
      "learning_rate": 0.0003792857142857143,
      "loss": 0.0534,
      "step": 1690
    },
    {
      "epoch": 1.6617790811339197,
      "grad_norm": 0.8470299243927002,
      "learning_rate": 0.0003785714285714286,
      "loss": 0.0453,
      "step": 1700
    },
    {
      "epoch": 1.6715542521994133,
      "grad_norm": 0.8350046873092651,
      "learning_rate": 0.00037785714285714283,
      "loss": 0.0482,
      "step": 1710
    },
    {
      "epoch": 1.681329423264907,
      "grad_norm": 2.245373249053955,
      "learning_rate": 0.0003771428571428572,
      "loss": 0.0996,
      "step": 1720
    },
    {
      "epoch": 1.6911045943304008,
      "grad_norm": 1.1746522188186646,
      "learning_rate": 0.00037642857142857145,
      "loss": 0.0657,
      "step": 1730
    },
    {
      "epoch": 1.7008797653958945,
      "grad_norm": 0.22571764886379242,
      "learning_rate": 0.00037571428571428575,
      "loss": 0.0542,
      "step": 1740
    },
    {
      "epoch": 1.710654936461388,
      "grad_norm": 2.052438497543335,
      "learning_rate": 0.000375,
      "loss": 0.0599,
      "step": 1750
    },
    {
      "epoch": 1.7204301075268817,
      "grad_norm": 0.5676813721656799,
      "learning_rate": 0.00037428571428571426,
      "loss": 0.0754,
      "step": 1760
    },
    {
      "epoch": 1.7302052785923754,
      "grad_norm": 1.641327977180481,
      "learning_rate": 0.00037357142857142857,
      "loss": 0.0698,
      "step": 1770
    },
    {
      "epoch": 1.739980449657869,
      "grad_norm": 0.11875827610492706,
      "learning_rate": 0.0003728571428571428,
      "loss": 0.071,
      "step": 1780
    },
    {
      "epoch": 1.7497556207233627,
      "grad_norm": 0.2898338735103607,
      "learning_rate": 0.0003721428571428572,
      "loss": 0.0582,
      "step": 1790
    },
    {
      "epoch": 1.7595307917888563,
      "grad_norm": 1.057012677192688,
      "learning_rate": 0.00037142857142857143,
      "loss": 0.0604,
      "step": 1800
    },
    {
      "epoch": 1.76930596285435,
      "grad_norm": 0.4930988550186157,
      "learning_rate": 0.00037071428571428574,
      "loss": 0.0612,
      "step": 1810
    },
    {
      "epoch": 1.7790811339198436,
      "grad_norm": 0.3862529993057251,
      "learning_rate": 0.00037,
      "loss": 0.0541,
      "step": 1820
    },
    {
      "epoch": 1.7888563049853372,
      "grad_norm": 2.6235599517822266,
      "learning_rate": 0.0003692857142857143,
      "loss": 0.0725,
      "step": 1830
    },
    {
      "epoch": 1.7986314760508308,
      "grad_norm": 4.731061935424805,
      "learning_rate": 0.00036857142857142855,
      "loss": 0.0624,
      "step": 1840
    },
    {
      "epoch": 1.8084066471163245,
      "grad_norm": 0.09260830283164978,
      "learning_rate": 0.0003678571428571429,
      "loss": 0.047,
      "step": 1850
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 1.4492684602737427,
      "learning_rate": 0.00036714285714285717,
      "loss": 0.0653,
      "step": 1860
    },
    {
      "epoch": 1.827956989247312,
      "grad_norm": 0.15945544838905334,
      "learning_rate": 0.0003664285714285714,
      "loss": 0.0509,
      "step": 1870
    },
    {
      "epoch": 1.8377321603128056,
      "grad_norm": 1.6792042255401611,
      "learning_rate": 0.00036571428571428573,
      "loss": 0.05,
      "step": 1880
    },
    {
      "epoch": 1.8475073313782993,
      "grad_norm": 0.8394700884819031,
      "learning_rate": 0.000365,
      "loss": 0.0811,
      "step": 1890
    },
    {
      "epoch": 1.857282502443793,
      "grad_norm": 1.0252118110656738,
      "learning_rate": 0.0003642857142857143,
      "loss": 0.0638,
      "step": 1900
    },
    {
      "epoch": 1.8670576735092865,
      "grad_norm": 0.9019574522972107,
      "learning_rate": 0.00036357142857142854,
      "loss": 0.0607,
      "step": 1910
    },
    {
      "epoch": 1.8768328445747802,
      "grad_norm": 0.3579191565513611,
      "learning_rate": 0.0003628571428571429,
      "loss": 0.0592,
      "step": 1920
    },
    {
      "epoch": 1.8866080156402738,
      "grad_norm": 0.6053521037101746,
      "learning_rate": 0.00036214285714285716,
      "loss": 0.0855,
      "step": 1930
    },
    {
      "epoch": 1.8963831867057674,
      "grad_norm": 0.6028860807418823,
      "learning_rate": 0.00036142857142857146,
      "loss": 0.0621,
      "step": 1940
    },
    {
      "epoch": 1.906158357771261,
      "grad_norm": 0.2439429759979248,
      "learning_rate": 0.0003607142857142857,
      "loss": 0.0643,
      "step": 1950
    },
    {
      "epoch": 1.9159335288367547,
      "grad_norm": 1.1175512075424194,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.0699,
      "step": 1960
    },
    {
      "epoch": 1.9257086999022484,
      "grad_norm": 1.7823477983474731,
      "learning_rate": 0.0003592857142857143,
      "loss": 0.0797,
      "step": 1970
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.2628210186958313,
      "learning_rate": 0.0003585714285714286,
      "loss": 0.0508,
      "step": 1980
    },
    {
      "epoch": 1.9452590420332356,
      "grad_norm": 0.46157941222190857,
      "learning_rate": 0.0003578571428571429,
      "loss": 0.051,
      "step": 1990
    },
    {
      "epoch": 1.9550342130987293,
      "grad_norm": 0.3930290639400482,
      "learning_rate": 0.00035714285714285714,
      "loss": 0.0574,
      "step": 2000
    },
    {
      "epoch": 1.964809384164223,
      "grad_norm": 0.320666640996933,
      "learning_rate": 0.00035642857142857145,
      "loss": 0.0606,
      "step": 2010
    },
    {
      "epoch": 1.9745845552297165,
      "grad_norm": 0.6424376964569092,
      "learning_rate": 0.0003557142857142857,
      "loss": 0.0473,
      "step": 2020
    },
    {
      "epoch": 1.9843597262952102,
      "grad_norm": 0.14668132364749908,
      "learning_rate": 0.000355,
      "loss": 0.0549,
      "step": 2030
    },
    {
      "epoch": 1.9941348973607038,
      "grad_norm": 0.43613940477371216,
      "learning_rate": 0.00035428571428571426,
      "loss": 0.0513,
      "step": 2040
    },
    {
      "epoch": 2.0039100684261975,
      "grad_norm": 0.3619380295276642,
      "learning_rate": 0.0003535714285714286,
      "loss": 0.0481,
      "step": 2050
    },
    {
      "epoch": 2.013685239491691,
      "grad_norm": 0.03216063976287842,
      "learning_rate": 0.0003528571428571429,
      "loss": 0.0544,
      "step": 2060
    },
    {
      "epoch": 2.0234604105571847,
      "grad_norm": 0.3919655382633209,
      "learning_rate": 0.00035214285714285713,
      "loss": 0.038,
      "step": 2070
    },
    {
      "epoch": 2.0332355816226784,
      "grad_norm": 0.23517528176307678,
      "learning_rate": 0.00035142857142857144,
      "loss": 0.062,
      "step": 2080
    },
    {
      "epoch": 2.043010752688172,
      "grad_norm": 0.069134920835495,
      "learning_rate": 0.0003507142857142857,
      "loss": 0.0572,
      "step": 2090
    },
    {
      "epoch": 2.0527859237536656,
      "grad_norm": 0.5004438757896423,
      "learning_rate": 0.00035,
      "loss": 0.0465,
      "step": 2100
    },
    {
      "epoch": 2.0625610948191593,
      "grad_norm": 2.9655251502990723,
      "learning_rate": 0.0003492857142857143,
      "loss": 0.0897,
      "step": 2110
    },
    {
      "epoch": 2.072336265884653,
      "grad_norm": 0.9263331294059753,
      "learning_rate": 0.0003485714285714286,
      "loss": 0.0444,
      "step": 2120
    },
    {
      "epoch": 2.0821114369501466,
      "grad_norm": 7.444808006286621,
      "learning_rate": 0.00034785714285714286,
      "loss": 0.0552,
      "step": 2130
    },
    {
      "epoch": 2.09188660801564,
      "grad_norm": 4.959798336029053,
      "learning_rate": 0.00034714285714285717,
      "loss": 0.0515,
      "step": 2140
    },
    {
      "epoch": 2.101661779081134,
      "grad_norm": 0.4531690776348114,
      "learning_rate": 0.0003464285714285714,
      "loss": 0.0529,
      "step": 2150
    },
    {
      "epoch": 2.1114369501466275,
      "grad_norm": 2.1691770553588867,
      "learning_rate": 0.00034571428571428573,
      "loss": 0.0701,
      "step": 2160
    },
    {
      "epoch": 2.121212121212121,
      "grad_norm": 0.6416878700256348,
      "learning_rate": 0.000345,
      "loss": 0.0613,
      "step": 2170
    },
    {
      "epoch": 2.1309872922776147,
      "grad_norm": 0.4368356764316559,
      "learning_rate": 0.0003442857142857143,
      "loss": 0.0661,
      "step": 2180
    },
    {
      "epoch": 2.1407624633431084,
      "grad_norm": 0.09033103287220001,
      "learning_rate": 0.0003435714285714286,
      "loss": 0.0517,
      "step": 2190
    },
    {
      "epoch": 2.150537634408602,
      "grad_norm": 0.06755993515253067,
      "learning_rate": 0.00034285714285714285,
      "loss": 0.0384,
      "step": 2200
    },
    {
      "epoch": 2.1603128054740957,
      "grad_norm": 2.7943062782287598,
      "learning_rate": 0.00034214285714285716,
      "loss": 0.0657,
      "step": 2210
    },
    {
      "epoch": 2.1700879765395893,
      "grad_norm": 0.5517023205757141,
      "learning_rate": 0.0003414285714285714,
      "loss": 0.0521,
      "step": 2220
    },
    {
      "epoch": 2.179863147605083,
      "grad_norm": 0.643269419670105,
      "learning_rate": 0.0003407142857142857,
      "loss": 0.0432,
      "step": 2230
    },
    {
      "epoch": 2.1896383186705766,
      "grad_norm": 0.27543455362319946,
      "learning_rate": 0.00034,
      "loss": 0.051,
      "step": 2240
    },
    {
      "epoch": 2.19941348973607,
      "grad_norm": 0.07505695521831512,
      "learning_rate": 0.00033928571428571433,
      "loss": 0.0479,
      "step": 2250
    },
    {
      "epoch": 2.209188660801564,
      "grad_norm": 0.1139320358633995,
      "learning_rate": 0.0003385714285714286,
      "loss": 0.0594,
      "step": 2260
    },
    {
      "epoch": 2.2189638318670575,
      "grad_norm": 0.7087254524230957,
      "learning_rate": 0.00033785714285714284,
      "loss": 0.0548,
      "step": 2270
    },
    {
      "epoch": 2.228739002932551,
      "grad_norm": 0.6593661308288574,
      "learning_rate": 0.00033714285714285714,
      "loss": 0.0606,
      "step": 2280
    },
    {
      "epoch": 2.2385141739980448,
      "grad_norm": 0.6598489880561829,
      "learning_rate": 0.0003364285714285714,
      "loss": 0.0527,
      "step": 2290
    },
    {
      "epoch": 2.2482893450635384,
      "grad_norm": 0.4133738577365875,
      "learning_rate": 0.0003357142857142857,
      "loss": 0.0615,
      "step": 2300
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.6279475092887878,
      "learning_rate": 0.000335,
      "loss": 0.0455,
      "step": 2310
    },
    {
      "epoch": 2.2678396871945257,
      "grad_norm": 0.7482165694236755,
      "learning_rate": 0.0003342857142857143,
      "loss": 0.0499,
      "step": 2320
    },
    {
      "epoch": 2.2776148582600193,
      "grad_norm": 0.3982474207878113,
      "learning_rate": 0.00033357142857142857,
      "loss": 0.0519,
      "step": 2330
    },
    {
      "epoch": 2.2873900293255134,
      "grad_norm": 1.468752384185791,
      "learning_rate": 0.0003328571428571429,
      "loss": 0.0511,
      "step": 2340
    },
    {
      "epoch": 2.297165200391007,
      "grad_norm": 0.043347474187612534,
      "learning_rate": 0.00033214285714285713,
      "loss": 0.0505,
      "step": 2350
    },
    {
      "epoch": 2.3069403714565007,
      "grad_norm": 0.054857779294252396,
      "learning_rate": 0.00033142857142857144,
      "loss": 0.0483,
      "step": 2360
    },
    {
      "epoch": 2.3167155425219943,
      "grad_norm": 0.5111517906188965,
      "learning_rate": 0.00033071428571428575,
      "loss": 0.0497,
      "step": 2370
    },
    {
      "epoch": 2.326490713587488,
      "grad_norm": 0.16318148374557495,
      "learning_rate": 0.00033,
      "loss": 0.0463,
      "step": 2380
    },
    {
      "epoch": 2.3362658846529816,
      "grad_norm": 0.7316855192184448,
      "learning_rate": 0.0003292857142857143,
      "loss": 0.0465,
      "step": 2390
    },
    {
      "epoch": 2.346041055718475,
      "grad_norm": 0.12929999828338623,
      "learning_rate": 0.00032857142857142856,
      "loss": 0.054,
      "step": 2400
    },
    {
      "epoch": 2.355816226783969,
      "grad_norm": 0.3306310474872589,
      "learning_rate": 0.00032785714285714287,
      "loss": 0.0498,
      "step": 2410
    },
    {
      "epoch": 2.3655913978494625,
      "grad_norm": 0.21542330086231232,
      "learning_rate": 0.0003271428571428571,
      "loss": 0.0533,
      "step": 2420
    },
    {
      "epoch": 2.375366568914956,
      "grad_norm": 2.5922176837921143,
      "learning_rate": 0.0003264285714285714,
      "loss": 0.0545,
      "step": 2430
    },
    {
      "epoch": 2.3851417399804498,
      "grad_norm": 1.7512760162353516,
      "learning_rate": 0.00032571428571428573,
      "loss": 0.0505,
      "step": 2440
    },
    {
      "epoch": 2.3949169110459434,
      "grad_norm": 0.9931915998458862,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.0587,
      "step": 2450
    },
    {
      "epoch": 2.404692082111437,
      "grad_norm": 0.36056768894195557,
      "learning_rate": 0.0003242857142857143,
      "loss": 0.0481,
      "step": 2460
    },
    {
      "epoch": 2.4144672531769307,
      "grad_norm": 0.41543835401535034,
      "learning_rate": 0.0003235714285714286,
      "loss": 0.0566,
      "step": 2470
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 0.028855443000793457,
      "learning_rate": 0.00032285714285714285,
      "loss": 0.0452,
      "step": 2480
    },
    {
      "epoch": 2.434017595307918,
      "grad_norm": 0.8778060674667358,
      "learning_rate": 0.0003221428571428571,
      "loss": 0.0479,
      "step": 2490
    },
    {
      "epoch": 2.4437927663734116,
      "grad_norm": 0.0902625173330307,
      "learning_rate": 0.00032142857142857147,
      "loss": 0.0392,
      "step": 2500
    },
    {
      "epoch": 2.4535679374389052,
      "grad_norm": 1.3771305084228516,
      "learning_rate": 0.0003207142857142857,
      "loss": 0.0565,
      "step": 2510
    },
    {
      "epoch": 2.463343108504399,
      "grad_norm": 0.02648344449698925,
      "learning_rate": 0.00032,
      "loss": 0.052,
      "step": 2520
    },
    {
      "epoch": 2.4731182795698925,
      "grad_norm": 0.09044435620307922,
      "learning_rate": 0.0003192857142857143,
      "loss": 0.0459,
      "step": 2530
    },
    {
      "epoch": 2.482893450635386,
      "grad_norm": 1.005890130996704,
      "learning_rate": 0.0003185714285714286,
      "loss": 0.0456,
      "step": 2540
    },
    {
      "epoch": 2.4926686217008798,
      "grad_norm": 0.14616529643535614,
      "learning_rate": 0.00031785714285714284,
      "loss": 0.0429,
      "step": 2550
    },
    {
      "epoch": 2.5024437927663734,
      "grad_norm": 2.2435264587402344,
      "learning_rate": 0.00031714285714285715,
      "loss": 0.0638,
      "step": 2560
    },
    {
      "epoch": 2.512218963831867,
      "grad_norm": 0.14437732100486755,
      "learning_rate": 0.00031642857142857145,
      "loss": 0.0498,
      "step": 2570
    },
    {
      "epoch": 2.5219941348973607,
      "grad_norm": 0.09753433614969254,
      "learning_rate": 0.0003157142857142857,
      "loss": 0.0476,
      "step": 2580
    },
    {
      "epoch": 2.5317693059628543,
      "grad_norm": 2.560943365097046,
      "learning_rate": 0.000315,
      "loss": 0.0429,
      "step": 2590
    },
    {
      "epoch": 2.541544477028348,
      "grad_norm": 0.9958483576774597,
      "learning_rate": 0.00031428571428571427,
      "loss": 0.0545,
      "step": 2600
    },
    {
      "epoch": 2.5513196480938416,
      "grad_norm": 0.18821774423122406,
      "learning_rate": 0.0003135714285714286,
      "loss": 0.0653,
      "step": 2610
    },
    {
      "epoch": 2.5610948191593352,
      "grad_norm": 2.081662178039551,
      "learning_rate": 0.0003128571428571428,
      "loss": 0.0629,
      "step": 2620
    },
    {
      "epoch": 2.570869990224829,
      "grad_norm": 0.33352312445640564,
      "learning_rate": 0.0003121428571428572,
      "loss": 0.0398,
      "step": 2630
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.9704803228378296,
      "learning_rate": 0.00031142857142857144,
      "loss": 0.05,
      "step": 2640
    },
    {
      "epoch": 2.590420332355816,
      "grad_norm": 0.8872607350349426,
      "learning_rate": 0.00031071428571428575,
      "loss": 0.0639,
      "step": 2650
    },
    {
      "epoch": 2.60019550342131,
      "grad_norm": 0.7843403816223145,
      "learning_rate": 0.00031,
      "loss": 0.0466,
      "step": 2660
    },
    {
      "epoch": 2.6099706744868034,
      "grad_norm": 0.3276051878929138,
      "learning_rate": 0.0003092857142857143,
      "loss": 0.0472,
      "step": 2670
    },
    {
      "epoch": 2.619745845552297,
      "grad_norm": 0.7521031498908997,
      "learning_rate": 0.00030857142857142856,
      "loss": 0.0574,
      "step": 2680
    },
    {
      "epoch": 2.6295210166177907,
      "grad_norm": 0.10539508610963821,
      "learning_rate": 0.00030785714285714287,
      "loss": 0.0458,
      "step": 2690
    },
    {
      "epoch": 2.6392961876832843,
      "grad_norm": 1.2764445543289185,
      "learning_rate": 0.0003071428571428572,
      "loss": 0.0401,
      "step": 2700
    },
    {
      "epoch": 2.649071358748778,
      "grad_norm": 0.11640283465385437,
      "learning_rate": 0.0003064285714285714,
      "loss": 0.0544,
      "step": 2710
    },
    {
      "epoch": 2.6588465298142716,
      "grad_norm": 0.46920573711395264,
      "learning_rate": 0.00030571428571428573,
      "loss": 0.0698,
      "step": 2720
    },
    {
      "epoch": 2.6686217008797652,
      "grad_norm": 0.42780643701553345,
      "learning_rate": 0.000305,
      "loss": 0.0399,
      "step": 2730
    },
    {
      "epoch": 2.678396871945259,
      "grad_norm": 0.25291451811790466,
      "learning_rate": 0.0003042857142857143,
      "loss": 0.0585,
      "step": 2740
    },
    {
      "epoch": 2.688172043010753,
      "grad_norm": 0.6801682114601135,
      "learning_rate": 0.00030357142857142855,
      "loss": 0.0397,
      "step": 2750
    },
    {
      "epoch": 2.6979472140762466,
      "grad_norm": 0.12419727444648743,
      "learning_rate": 0.0003028571428571429,
      "loss": 0.0403,
      "step": 2760
    },
    {
      "epoch": 2.7077223851417402,
      "grad_norm": 0.05783294886350632,
      "learning_rate": 0.00030214285714285716,
      "loss": 0.0439,
      "step": 2770
    },
    {
      "epoch": 2.717497556207234,
      "grad_norm": 0.12500037252902985,
      "learning_rate": 0.0003014285714285714,
      "loss": 0.0507,
      "step": 2780
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.19243532419204712,
      "learning_rate": 0.0003007142857142857,
      "loss": 0.0456,
      "step": 2790
    },
    {
      "epoch": 2.737047898338221,
      "grad_norm": 1.2126699686050415,
      "learning_rate": 0.0003,
      "loss": 0.0467,
      "step": 2800
    },
    {
      "epoch": 2.746823069403715,
      "grad_norm": 0.4893585443496704,
      "learning_rate": 0.0002992857142857143,
      "loss": 0.0366,
      "step": 2810
    },
    {
      "epoch": 2.7565982404692084,
      "grad_norm": 0.13877516984939575,
      "learning_rate": 0.0002985714285714286,
      "loss": 0.0415,
      "step": 2820
    },
    {
      "epoch": 2.766373411534702,
      "grad_norm": 0.4521678686141968,
      "learning_rate": 0.0002978571428571429,
      "loss": 0.0561,
      "step": 2830
    },
    {
      "epoch": 2.7761485826001957,
      "grad_norm": 0.8327937126159668,
      "learning_rate": 0.00029714285714285715,
      "loss": 0.0564,
      "step": 2840
    },
    {
      "epoch": 2.7859237536656893,
      "grad_norm": 0.47416257858276367,
      "learning_rate": 0.00029642857142857145,
      "loss": 0.048,
      "step": 2850
    },
    {
      "epoch": 2.795698924731183,
      "grad_norm": 0.7029886245727539,
      "learning_rate": 0.0002957142857142857,
      "loss": 0.0528,
      "step": 2860
    },
    {
      "epoch": 2.8054740957966766,
      "grad_norm": 0.4642947018146515,
      "learning_rate": 0.000295,
      "loss": 0.0434,
      "step": 2870
    },
    {
      "epoch": 2.8152492668621703,
      "grad_norm": 0.42996880412101746,
      "learning_rate": 0.00029428571428571427,
      "loss": 0.0468,
      "step": 2880
    },
    {
      "epoch": 2.825024437927664,
      "grad_norm": 0.5407069325447083,
      "learning_rate": 0.0002935714285714286,
      "loss": 0.0483,
      "step": 2890
    },
    {
      "epoch": 2.8347996089931575,
      "grad_norm": 2.7549350261688232,
      "learning_rate": 0.0002928571428571429,
      "loss": 0.0632,
      "step": 2900
    },
    {
      "epoch": 2.844574780058651,
      "grad_norm": 0.3113798201084137,
      "learning_rate": 0.00029214285714285713,
      "loss": 0.0525,
      "step": 2910
    },
    {
      "epoch": 2.854349951124145,
      "grad_norm": 1.2765536308288574,
      "learning_rate": 0.00029142857142857144,
      "loss": 0.0524,
      "step": 2920
    },
    {
      "epoch": 2.8641251221896384,
      "grad_norm": 0.08783843368291855,
      "learning_rate": 0.0002907142857142857,
      "loss": 0.0422,
      "step": 2930
    },
    {
      "epoch": 2.873900293255132,
      "grad_norm": 0.557056188583374,
      "learning_rate": 0.00029,
      "loss": 0.0482,
      "step": 2940
    },
    {
      "epoch": 2.8836754643206257,
      "grad_norm": 0.20702707767486572,
      "learning_rate": 0.0002892857142857143,
      "loss": 0.0504,
      "step": 2950
    },
    {
      "epoch": 2.8934506353861194,
      "grad_norm": 1.869444489479065,
      "learning_rate": 0.0002885714285714286,
      "loss": 0.0578,
      "step": 2960
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.444354772567749,
      "learning_rate": 0.00028785714285714287,
      "loss": 0.042,
      "step": 2970
    },
    {
      "epoch": 2.9130009775171066,
      "grad_norm": 0.6428873538970947,
      "learning_rate": 0.0002871428571428572,
      "loss": 0.058,
      "step": 2980
    },
    {
      "epoch": 2.9227761485826003,
      "grad_norm": 1.3170084953308105,
      "learning_rate": 0.00028642857142857143,
      "loss": 0.0454,
      "step": 2990
    },
    {
      "epoch": 2.932551319648094,
      "grad_norm": 0.793518602848053,
      "learning_rate": 0.0002857142857142857,
      "loss": 0.0411,
      "step": 3000
    },
    {
      "epoch": 2.9423264907135875,
      "grad_norm": 0.017626669257879257,
      "learning_rate": 0.000285,
      "loss": 0.055,
      "step": 3010
    },
    {
      "epoch": 2.952101661779081,
      "grad_norm": 1.6733330488204956,
      "learning_rate": 0.0002842857142857143,
      "loss": 0.0507,
      "step": 3020
    },
    {
      "epoch": 2.961876832844575,
      "grad_norm": 0.13941022753715515,
      "learning_rate": 0.0002835714285714286,
      "loss": 0.0566,
      "step": 3030
    },
    {
      "epoch": 2.9716520039100685,
      "grad_norm": 0.19049032032489777,
      "learning_rate": 0.00028285714285714286,
      "loss": 0.0573,
      "step": 3040
    },
    {
      "epoch": 2.981427174975562,
      "grad_norm": 0.18956713378429413,
      "learning_rate": 0.00028214285714285716,
      "loss": 0.0543,
      "step": 3050
    },
    {
      "epoch": 2.9912023460410557,
      "grad_norm": 0.33016282320022583,
      "learning_rate": 0.0002814285714285714,
      "loss": 0.0504,
      "step": 3060
    },
    {
      "epoch": 3.0009775171065494,
      "grad_norm": 0.3811204135417938,
      "learning_rate": 0.0002807142857142857,
      "loss": 0.0541,
      "step": 3070
    },
    {
      "epoch": 3.010752688172043,
      "grad_norm": 0.6770540475845337,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.0476,
      "step": 3080
    },
    {
      "epoch": 3.0205278592375366,
      "grad_norm": 0.5325613021850586,
      "learning_rate": 0.0002792857142857143,
      "loss": 0.045,
      "step": 3090
    },
    {
      "epoch": 3.0303030303030303,
      "grad_norm": 0.10270298272371292,
      "learning_rate": 0.0002785714285714286,
      "loss": 0.0426,
      "step": 3100
    },
    {
      "epoch": 3.040078201368524,
      "grad_norm": 0.04250131547451019,
      "learning_rate": 0.00027785714285714284,
      "loss": 0.0395,
      "step": 3110
    },
    {
      "epoch": 3.0498533724340176,
      "grad_norm": 0.4422298073768616,
      "learning_rate": 0.00027714285714285715,
      "loss": 0.0381,
      "step": 3120
    },
    {
      "epoch": 3.059628543499511,
      "grad_norm": 0.7763152718544006,
      "learning_rate": 0.0002764285714285714,
      "loss": 0.0477,
      "step": 3130
    },
    {
      "epoch": 3.069403714565005,
      "grad_norm": 0.371843546628952,
      "learning_rate": 0.0002757142857142857,
      "loss": 0.0403,
      "step": 3140
    },
    {
      "epoch": 3.0791788856304985,
      "grad_norm": 1.0746474266052246,
      "learning_rate": 0.000275,
      "loss": 0.0478,
      "step": 3150
    },
    {
      "epoch": 3.088954056695992,
      "grad_norm": 0.37276965379714966,
      "learning_rate": 0.0002742857142857143,
      "loss": 0.0331,
      "step": 3160
    },
    {
      "epoch": 3.0987292277614857,
      "grad_norm": 0.0348564051091671,
      "learning_rate": 0.0002735714285714286,
      "loss": 0.0419,
      "step": 3170
    },
    {
      "epoch": 3.1085043988269794,
      "grad_norm": 0.19226014614105225,
      "learning_rate": 0.0002728571428571429,
      "loss": 0.0383,
      "step": 3180
    },
    {
      "epoch": 3.118279569892473,
      "grad_norm": 0.11617859452962875,
      "learning_rate": 0.00027214285714285714,
      "loss": 0.0396,
      "step": 3190
    },
    {
      "epoch": 3.1280547409579667,
      "grad_norm": 0.6512064337730408,
      "learning_rate": 0.0002714285714285714,
      "loss": 0.0383,
      "step": 3200
    },
    {
      "epoch": 3.1378299120234603,
      "grad_norm": 0.5969706177711487,
      "learning_rate": 0.00027071428571428575,
      "loss": 0.0392,
      "step": 3210
    },
    {
      "epoch": 3.147605083088954,
      "grad_norm": 0.44152382016181946,
      "learning_rate": 0.00027,
      "loss": 0.0571,
      "step": 3220
    },
    {
      "epoch": 3.1573802541544476,
      "grad_norm": 0.7687763571739197,
      "learning_rate": 0.0002692857142857143,
      "loss": 0.04,
      "step": 3230
    },
    {
      "epoch": 3.167155425219941,
      "grad_norm": 0.9144178628921509,
      "learning_rate": 0.00026857142857142856,
      "loss": 0.039,
      "step": 3240
    },
    {
      "epoch": 3.176930596285435,
      "grad_norm": 0.39098235964775085,
      "learning_rate": 0.00026785714285714287,
      "loss": 0.0504,
      "step": 3250
    },
    {
      "epoch": 3.1867057673509285,
      "grad_norm": 0.28275322914123535,
      "learning_rate": 0.0002671428571428571,
      "loss": 0.038,
      "step": 3260
    },
    {
      "epoch": 3.196480938416422,
      "grad_norm": 0.4170970916748047,
      "learning_rate": 0.00026642857142857143,
      "loss": 0.0605,
      "step": 3270
    },
    {
      "epoch": 3.2062561094819158,
      "grad_norm": 0.04272500425577164,
      "learning_rate": 0.00026571428571428574,
      "loss": 0.066,
      "step": 3280
    },
    {
      "epoch": 3.2160312805474094,
      "grad_norm": 0.973529577255249,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.0396,
      "step": 3290
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 0.1941029131412506,
      "learning_rate": 0.0002642857142857143,
      "loss": 0.034,
      "step": 3300
    },
    {
      "epoch": 3.2355816226783967,
      "grad_norm": 0.23836465179920197,
      "learning_rate": 0.00026357142857142855,
      "loss": 0.038,
      "step": 3310
    },
    {
      "epoch": 3.2453567937438903,
      "grad_norm": 0.051475830376148224,
      "learning_rate": 0.00026285714285714286,
      "loss": 0.04,
      "step": 3320
    },
    {
      "epoch": 3.255131964809384,
      "grad_norm": 0.6473431587219238,
      "learning_rate": 0.0002621428571428571,
      "loss": 0.0441,
      "step": 3330
    },
    {
      "epoch": 3.2649071358748776,
      "grad_norm": 0.294260174036026,
      "learning_rate": 0.00026142857142857147,
      "loss": 0.0438,
      "step": 3340
    },
    {
      "epoch": 3.274682306940371,
      "grad_norm": 0.7520986199378967,
      "learning_rate": 0.0002607142857142857,
      "loss": 0.0417,
      "step": 3350
    },
    {
      "epoch": 3.2844574780058653,
      "grad_norm": 0.15757548809051514,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.0362,
      "step": 3360
    },
    {
      "epoch": 3.294232649071359,
      "grad_norm": 0.8607863783836365,
      "learning_rate": 0.0002592857142857143,
      "loss": 0.0574,
      "step": 3370
    },
    {
      "epoch": 3.3040078201368526,
      "grad_norm": 0.19825781881809235,
      "learning_rate": 0.0002585714285714286,
      "loss": 0.0383,
      "step": 3380
    },
    {
      "epoch": 3.313782991202346,
      "grad_norm": 0.13650555908679962,
      "learning_rate": 0.00025785714285714284,
      "loss": 0.0341,
      "step": 3390
    },
    {
      "epoch": 3.32355816226784,
      "grad_norm": 0.00849965587258339,
      "learning_rate": 0.0002571428571428571,
      "loss": 0.0416,
      "step": 3400
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.9635704755783081,
      "learning_rate": 0.00025642857142857146,
      "loss": 0.0614,
      "step": 3410
    },
    {
      "epoch": 3.343108504398827,
      "grad_norm": 0.24965539574623108,
      "learning_rate": 0.0002557142857142857,
      "loss": 0.0415,
      "step": 3420
    },
    {
      "epoch": 3.3528836754643208,
      "grad_norm": 0.012707246467471123,
      "learning_rate": 0.000255,
      "loss": 0.0474,
      "step": 3430
    },
    {
      "epoch": 3.3626588465298144,
      "grad_norm": 0.0447627417743206,
      "learning_rate": 0.00025428571428571427,
      "loss": 0.041,
      "step": 3440
    },
    {
      "epoch": 3.372434017595308,
      "grad_norm": 0.8578139543533325,
      "learning_rate": 0.0002535714285714286,
      "loss": 0.0441,
      "step": 3450
    },
    {
      "epoch": 3.3822091886608017,
      "grad_norm": 0.5400280356407166,
      "learning_rate": 0.00025285714285714283,
      "loss": 0.0454,
      "step": 3460
    },
    {
      "epoch": 3.3919843597262953,
      "grad_norm": 0.1941622942686081,
      "learning_rate": 0.0002521428571428572,
      "loss": 0.0478,
      "step": 3470
    },
    {
      "epoch": 3.401759530791789,
      "grad_norm": 0.36234250664711,
      "learning_rate": 0.00025142857142857145,
      "loss": 0.0403,
      "step": 3480
    },
    {
      "epoch": 3.4115347018572826,
      "grad_norm": 0.05828769877552986,
      "learning_rate": 0.00025071428571428575,
      "loss": 0.0455,
      "step": 3490
    },
    {
      "epoch": 3.421309872922776,
      "grad_norm": 0.8714934587478638,
      "learning_rate": 0.00025,
      "loss": 0.0421,
      "step": 3500
    },
    {
      "epoch": 3.43108504398827,
      "grad_norm": 0.037202317267656326,
      "learning_rate": 0.00024928571428571426,
      "loss": 0.0312,
      "step": 3510
    },
    {
      "epoch": 3.4408602150537635,
      "grad_norm": 0.4879288971424103,
      "learning_rate": 0.00024857142857142857,
      "loss": 0.033,
      "step": 3520
    },
    {
      "epoch": 3.450635386119257,
      "grad_norm": 0.7577947974205017,
      "learning_rate": 0.00024785714285714287,
      "loss": 0.0524,
      "step": 3530
    },
    {
      "epoch": 3.4604105571847508,
      "grad_norm": 0.0683925449848175,
      "learning_rate": 0.0002471428571428571,
      "loss": 0.0405,
      "step": 3540
    },
    {
      "epoch": 3.4701857282502444,
      "grad_norm": 0.4918545186519623,
      "learning_rate": 0.00024642857142857143,
      "loss": 0.0482,
      "step": 3550
    },
    {
      "epoch": 3.479960899315738,
      "grad_norm": 0.18632586300373077,
      "learning_rate": 0.00024571428571428574,
      "loss": 0.0433,
      "step": 3560
    },
    {
      "epoch": 3.4897360703812317,
      "grad_norm": 0.47539737820625305,
      "learning_rate": 0.000245,
      "loss": 0.0396,
      "step": 3570
    },
    {
      "epoch": 3.4995112414467253,
      "grad_norm": 15.149669647216797,
      "learning_rate": 0.0002442857142857143,
      "loss": 0.0385,
      "step": 3580
    },
    {
      "epoch": 3.509286412512219,
      "grad_norm": 0.638496994972229,
      "learning_rate": 0.00024357142857142858,
      "loss": 0.0471,
      "step": 3590
    },
    {
      "epoch": 3.5190615835777126,
      "grad_norm": 1.2654212713241577,
      "learning_rate": 0.00024285714285714286,
      "loss": 0.0511,
      "step": 3600
    },
    {
      "epoch": 3.5288367546432062,
      "grad_norm": 1.196696162223816,
      "learning_rate": 0.00024214285714285714,
      "loss": 0.0407,
      "step": 3610
    },
    {
      "epoch": 3.5386119257087,
      "grad_norm": 4.42251443862915,
      "learning_rate": 0.00024142857142857145,
      "loss": 0.038,
      "step": 3620
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 0.16781550645828247,
      "learning_rate": 0.00024071428571428573,
      "loss": 0.0491,
      "step": 3630
    },
    {
      "epoch": 3.558162267839687,
      "grad_norm": 1.7030538320541382,
      "learning_rate": 0.00024,
      "loss": 0.0479,
      "step": 3640
    },
    {
      "epoch": 3.567937438905181,
      "grad_norm": 0.10327647626399994,
      "learning_rate": 0.0002392857142857143,
      "loss": 0.0433,
      "step": 3650
    },
    {
      "epoch": 3.5777126099706744,
      "grad_norm": 0.09737547487020493,
      "learning_rate": 0.00023857142857142857,
      "loss": 0.0446,
      "step": 3660
    },
    {
      "epoch": 3.587487781036168,
      "grad_norm": 0.23371422290802002,
      "learning_rate": 0.00023785714285714285,
      "loss": 0.0367,
      "step": 3670
    },
    {
      "epoch": 3.5972629521016617,
      "grad_norm": 0.8069459795951843,
      "learning_rate": 0.00023714285714285715,
      "loss": 0.0481,
      "step": 3680
    },
    {
      "epoch": 3.6070381231671553,
      "grad_norm": 0.8375679850578308,
      "learning_rate": 0.00023642857142857143,
      "loss": 0.0538,
      "step": 3690
    },
    {
      "epoch": 3.616813294232649,
      "grad_norm": 0.4682459533214569,
      "learning_rate": 0.0002357142857142857,
      "loss": 0.0451,
      "step": 3700
    },
    {
      "epoch": 3.6265884652981426,
      "grad_norm": 0.9757556915283203,
      "learning_rate": 0.000235,
      "loss": 0.0432,
      "step": 3710
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 1.4518561363220215,
      "learning_rate": 0.0002342857142857143,
      "loss": 0.043,
      "step": 3720
    },
    {
      "epoch": 3.64613880742913,
      "grad_norm": 0.19943717122077942,
      "learning_rate": 0.00023357142857142858,
      "loss": 0.0348,
      "step": 3730
    },
    {
      "epoch": 3.6559139784946235,
      "grad_norm": 0.3278788626194,
      "learning_rate": 0.00023285714285714286,
      "loss": 0.0368,
      "step": 3740
    },
    {
      "epoch": 3.665689149560117,
      "grad_norm": 0.11831513792276382,
      "learning_rate": 0.00023214285714285717,
      "loss": 0.0318,
      "step": 3750
    },
    {
      "epoch": 3.675464320625611,
      "grad_norm": 0.2936321496963501,
      "learning_rate": 0.00023142857142857142,
      "loss": 0.0478,
      "step": 3760
    },
    {
      "epoch": 3.6852394916911044,
      "grad_norm": 0.24432989954948425,
      "learning_rate": 0.0002307142857142857,
      "loss": 0.0551,
      "step": 3770
    },
    {
      "epoch": 3.6950146627565985,
      "grad_norm": 0.434979110956192,
      "learning_rate": 0.00023,
      "loss": 0.0548,
      "step": 3780
    },
    {
      "epoch": 3.704789833822092,
      "grad_norm": 0.6956176161766052,
      "learning_rate": 0.0002292857142857143,
      "loss": 0.0323,
      "step": 3790
    },
    {
      "epoch": 3.714565004887586,
      "grad_norm": 0.7082581520080566,
      "learning_rate": 0.00022857142857142857,
      "loss": 0.0413,
      "step": 3800
    },
    {
      "epoch": 3.7243401759530794,
      "grad_norm": 0.9479883909225464,
      "learning_rate": 0.00022785714285714287,
      "loss": 0.038,
      "step": 3810
    },
    {
      "epoch": 3.734115347018573,
      "grad_norm": 0.584121823310852,
      "learning_rate": 0.00022714285714285715,
      "loss": 0.0466,
      "step": 3820
    },
    {
      "epoch": 3.7438905180840667,
      "grad_norm": 0.15694333612918854,
      "learning_rate": 0.00022642857142857143,
      "loss": 0.0336,
      "step": 3830
    },
    {
      "epoch": 3.7536656891495603,
      "grad_norm": 0.025848716497421265,
      "learning_rate": 0.00022571428571428571,
      "loss": 0.0492,
      "step": 3840
    },
    {
      "epoch": 3.763440860215054,
      "grad_norm": 0.41314229369163513,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.0447,
      "step": 3850
    },
    {
      "epoch": 3.7732160312805476,
      "grad_norm": 0.3499166667461395,
      "learning_rate": 0.0002242857142857143,
      "loss": 0.0417,
      "step": 3860
    },
    {
      "epoch": 3.7829912023460412,
      "grad_norm": 0.8801527619361877,
      "learning_rate": 0.00022357142857142855,
      "loss": 0.0376,
      "step": 3870
    },
    {
      "epoch": 3.792766373411535,
      "grad_norm": 0.37555962800979614,
      "learning_rate": 0.00022285714285714286,
      "loss": 0.0471,
      "step": 3880
    },
    {
      "epoch": 3.8025415444770285,
      "grad_norm": 2.5697391033172607,
      "learning_rate": 0.00022214285714285714,
      "loss": 0.0404,
      "step": 3890
    },
    {
      "epoch": 3.812316715542522,
      "grad_norm": 0.42269957065582275,
      "learning_rate": 0.00022142857142857142,
      "loss": 0.0437,
      "step": 3900
    },
    {
      "epoch": 3.822091886608016,
      "grad_norm": 1.1987303495407104,
      "learning_rate": 0.00022071428571428573,
      "loss": 0.0469,
      "step": 3910
    },
    {
      "epoch": 3.8318670576735094,
      "grad_norm": 0.7190418243408203,
      "learning_rate": 0.00022,
      "loss": 0.0426,
      "step": 3920
    },
    {
      "epoch": 3.841642228739003,
      "grad_norm": 0.13818885385990143,
      "learning_rate": 0.0002192857142857143,
      "loss": 0.0365,
      "step": 3930
    },
    {
      "epoch": 3.8514173998044967,
      "grad_norm": 0.07337404787540436,
      "learning_rate": 0.0002185714285714286,
      "loss": 0.0298,
      "step": 3940
    },
    {
      "epoch": 3.8611925708699903,
      "grad_norm": 0.18479536473751068,
      "learning_rate": 0.00021785714285714287,
      "loss": 0.0443,
      "step": 3950
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.13592977821826935,
      "learning_rate": 0.00021714285714285715,
      "loss": 0.0437,
      "step": 3960
    },
    {
      "epoch": 3.8807429130009776,
      "grad_norm": 0.021289397031068802,
      "learning_rate": 0.00021642857142857143,
      "loss": 0.0406,
      "step": 3970
    },
    {
      "epoch": 3.8905180840664713,
      "grad_norm": 0.23450082540512085,
      "learning_rate": 0.00021571428571428571,
      "loss": 0.0469,
      "step": 3980
    },
    {
      "epoch": 3.900293255131965,
      "grad_norm": 0.41748175024986267,
      "learning_rate": 0.000215,
      "loss": 0.0416,
      "step": 3990
    },
    {
      "epoch": 3.9100684261974585,
      "grad_norm": 0.05888950824737549,
      "learning_rate": 0.00021428571428571427,
      "loss": 0.0345,
      "step": 4000
    }
  ],
  "logging_steps": 10,
  "max_steps": 7000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.766149452153569e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
